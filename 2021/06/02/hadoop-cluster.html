<!doctype html><html lang=zh-cn dir=content/zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=content-security-policy content="upgrade-insecure-requests"><title>HADOOP-集群部署 - 路无止境！</title><meta name=keywords content="博客,架构师,思考,读书,笔记,技术,分享,云"><meta name=author content="Etaon"><meta property="og:title" content="HADOOP-集群部署"><meta property="og:site_name" content="路无止境！"><meta property="og:image" content="/img/author.jpg"><meta name=title content="HADOOP-集群部署 - 路无止境！"><meta name=description content="欢迎来到ETAON空间站，个人主要专注于Infra系统架构，私有/公有云产品，售前及微服务解决方案。"><link rel="shortcut icon" href=/img/favicon.ico><link rel=apple-touch-icon href=/img/apple-touch-icon.png><link rel=apple-touch-icon-precomposed href=/img/apple-touch-icon.png><link href=//cdn.bootcdn.net/ajax/libs/font-awesome/4.6.2/css/font-awesome.min.css rel=stylesheet type=text/css><link href=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.css rel=stylesheet><link href=/css/main.css rel=stylesheet type=text/css><link href=/css/syntax.css rel=stylesheet type=text/css></head><body itemscope itemtype=http://schema.org/WebPage lang=zh-hans><div class="container one-collumn sidebar-position-left page-home"><div class=headband></div><header id=header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle role=button style=opacity:1;top:0><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div></div><div class=site-meta><div class=multi-lang-switch><i class="fa fa-fw fa-language" style=margin-right:5px></i>
<a class=lang-link id=zh-cn href=#>学习</a></div><div class=custom-logo-site-title><a href=/ class=brand rel=start><span class=logo-line-before><i></i></span>
<span class=site-title>路无止境！</span>
<span class=logo-line-after><i></i></span></a></div><p class=site-subtitle>没有伞的孩子要学会努力奔跑!</p></div><div class=site-nav-right><div class="toggle popup-trigger" style=opacity:1;top:0><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul id=menu class=menu><li class=menu-item><a href=/ rel=section><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class=menu-item><a href=/post rel=section><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class=menu-item><a href=/about.html rel=section><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于我</a></li><li class=menu-item><a href=/404.html rel=section><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益404</a></li><li class="menu-item menu-item-search"><a href=javascript:; class=popup-trigger><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class=site-search><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class=search-icon><i class="fa fa-search"></i></span>
<span class=popup-btn-close><i class="fa fa-times-circle"></i></span><div class=local-search-input-wrapper><input autocomplete=off placeholder=搜索关键字... spellcheck=false type=text id=local-search-input autocapitalize=none autocorrect=off></div></div><div id=local-search-result></div></div></div></nav></div></header><main id=main class=main><div class=main-inner><div class=content-wrap><div id=content class=content><section id=posts class=posts-expand><article class="post post-type-normal" itemscope itemtype=http://schema.org/Article><header class=post-header><h1 class=post-title itemprop="name headline" style=font-weight:700><a class=post-title-link href=https://www.etaon.top/2021/06/02/hadoop-cluster.html itemprop=url>HADOOP-集群部署</a></h1></header><div class=post-body itemprop=articleBody><h2 id=前期准备>前期准备</h2><p>使用三台主机，每台安装好JDK和Hadoop
<img src="https://img-blog.csdnimg.cn/202106021638218.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzM5NDcyNA==,size_16,color_FFFFFF,t_70" alt=在这里插入图片描述></p><p>参考：<a href="https://editor.csdn.net/md/?articleId=117447607">Hadoop学习笔记&ndash;单台安装</a></p><h3 id=同步小技巧>同步小技巧</h3><h4 id=scp--rsync--编写xsync>scp&ndash;rsync&ndash;编写xsync</h4><p>scp是主机之间安全拷贝数据的工具，一般的语法为</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>scp  -r  $pdir/$fname  $user@$host:$pdir/$fname
</span></span></code></pre></div><p>q其中-r表示递归</p><p>rsync是远程同步工具，只对差异化的文件更新。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>rsync  -av  $pdir/$fname  $user@$host:$pdir/$fname
</span></span></code></pre></div><p>-a 归档拷贝
-v 显示复制过程</p><p>编写脚本xsync，自动完成同步</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#080>#!/bin/bash
</span></span></span><span style=display:flex><span><span style=color:#080></span><span style=color:#080;font-style:italic>#1. Judge the number of parameters</span>
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>if</span> <span style=color:#666>[</span> <span style=color:#b8860b>$#</span> -lt <span style=color:#666>1</span> <span style=color:#666>]</span>
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>then</span>
</span></span><span style=display:flex><span>  <span style=color:#a2f>echo</span> Not Enough Arguement!
</span></span><span style=display:flex><span>  exit;
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>fi</span>
</span></span><span style=display:flex><span><span style=color:#080;font-style:italic>#2.Traverse all hosts</span>
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> host in h102 h103 h104 <span style=color:#080;font-style:italic>#用到的所有主机</span>
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>do</span>
</span></span><span style=display:flex><span>  <span style=color:#a2f>echo</span> <span style=color:#666>==============================</span><span style=color:#b8860b>$host</span><span style=color:#666>==============================</span>
</span></span><span style=display:flex><span>  <span style=color:#080;font-style:italic>#3.Traverse all foulders and send</span>
</span></span><span style=display:flex><span>  <span style=color:#a2f;font-weight:700>for</span> file in <span style=color:#b8860b>$@</span>
</span></span><span style=display:flex><span>  <span style=color:#a2f;font-weight:700>do</span>
</span></span><span style=display:flex><span>    <span style=color:#080;font-style:italic>#4. Determine whether the file exists</span>
</span></span><span style=display:flex><span>        <span style=color:#a2f;font-weight:700>if</span> <span style=color:#666>[</span> -e <span style=color:#b8860b>$file</span> <span style=color:#666>]</span>
</span></span><span style=display:flex><span>          <span style=color:#a2f;font-weight:700>then</span>
</span></span><span style=display:flex><span>            <span style=color:#080;font-style:italic>#5. Get father foulder</span>
</span></span><span style=display:flex><span>                <span style=color:#b8860b>pdir</span><span style=color:#666>=</span><span style=color:#a2f;font-weight:700>$(</span><span style=color:#a2f>cd</span> -P <span style=color:#a2f;font-weight:700>$(</span>dirname <span style=color:#b8860b>$file</span><span style=color:#a2f;font-weight:700>)</span>; <span style=color:#a2f>pwd</span><span style=color:#a2f;font-weight:700>)</span>
</span></span><span style=display:flex><span>                <span style=color:#080;font-style:italic>#6.Get the name of current file</span>
</span></span><span style=display:flex><span>                <span style=color:#b8860b>fname</span><span style=color:#666>=</span><span style=color:#a2f;font-weight:700>$(</span>basename <span style=color:#b8860b>$fiel</span><span style=color:#a2f;font-weight:700>)</span>
</span></span><span style=display:flex><span>                ssh <span style=color:#b8860b>$host</span> <span style=color:#b44>&#34;mkdir -p </span><span style=color:#b8860b>$pdir</span><span style=color:#b44>&#34;</span>
</span></span><span style=display:flex><span>                rsync -av <span style=color:#b8860b>$pdir</span>/<span style=color:#b8860b>$file</span> <span style=color:#b8860b>$host</span>:<span style=color:#b8860b>$pdir</span>
</span></span><span style=display:flex><span>      <span style=color:#a2f;font-weight:700>else</span>
</span></span><span style=display:flex><span>            <span style=color:#a2f>echo</span> &amp;file doesNOT exists!
</span></span><span style=display:flex><span>        <span style=color:#a2f;font-weight:700>fi</span>
</span></span><span style=display:flex><span>  <span style=color:#a2f;font-weight:700>done</span>
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>done</span>
</span></span></code></pre></div><p>注意赋予+x可执行以及执行路径。</p><h4 id=ssh免密登录>SSH免密登录</h4><p><img src="https://img-blog.csdnimg.cn/20210602114436397.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzM5NDcyNA==,size_16,color_FFFFFF,t_70" alt=在这里插入图片描述>
使用命令：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>ssh-keygen -t rsa
</span></span><span style=display:flex><span>ssh-copy-id $hostname
</span></span></code></pre></div><p>如果有 ssh h102不成功，查看log</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>[zyi@h102 ~]$ sudo cat /var/log/secure
</span></span><span style=display:flex><span>。。。。
</span></span><span style=display:flex><span>Jun  1 09:08:35 h102 sshd[5829]: Disconnected from 192.168.110.84 port 43308
</span></span><span style=display:flex><span>Jun  1 09:08:35 h102 sshd[5825]: pam_unix(sshd:session): session closed for user zyi
</span></span><span style=display:flex><span>Jun  1 09:09:23 h102 sshd[5853]: Connection closed by 192.168.110.83 port 43172 [preauth]
</span></span><span style=display:flex><span>Jun  1 09:09:23 h102 sshd[5855]: Authentication refused: bad ownership or modes for directory /home/zyi
</span></span></code></pre></div><p>解决方法：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>chmod g-w /home/zyi
</span></span><span style=display:flex><span>Sysytemctl restart sshd
</span></span></code></pre></div><p>另外，SSH进行认证的过程中除了对用户目录有权限要求外，对 .ssh 文件夹和 authorized_keys 文件同样也要限制，如果日志中提示这两个的问题，可以通过如下方式进行修改：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>chmod 700 /home/skyler/.ssh
</span></span><span style=display:flex><span>chmod 600 /home/skyler/.ssh/authorized_keys
</span></span></code></pre></div><p>例子：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>[zyi@h104 ~]$ sudo chmod g-w /home/zyi
</span></span><span style=display:flex><span>[zyi@h104 ~]$ sudo chmod 700 ./.ssh
</span></span><span style=display:flex><span>[zyi@h104 ~]$ sudo chmod 600 ./.ssh/authorized_keys
</span></span><span style=display:flex><span>[zyi@h104 ~]$ sudo systemctl restart sshd
</span></span><span style=display:flex><span>[zyi@h104 ~]$ ssh h102
</span></span><span style=display:flex><span>Last failed login: Tue Jun  1 09:15:06 EDT 2021 from h103 on ssh:notty
</span></span><span style=display:flex><span>There were 2 failed login attempts since the last successful login.
</span></span><span style=display:flex><span>Last login: Tue Jun  1 09:13:29 2021 from h103
</span></span></code></pre></div><h2 id=集群规划>集群规划</h2><table><thead><tr><th>&ndash;</th><th>Hadoop102</th><th>Hadoop103</th><th>Hadoop104</th></tr></thead><tbody><tr><td>HDFS</td><td><strong>NameNode</strong> DataNode</td><td>DataNode</td><td><strong>SecondaryNameNode</strong> DataNode</td></tr><tr><td>YARN</td><td>NodeManager</td><td><strong>ResourceManager</strong> NodeManager</td><td>NodeManager</td></tr></tbody></table><p>➢ NameNode和 SecondaryNameNode都很消耗内存，不要安装在同一台服务器</p><p>➢ ResourceManager也很消耗内存，不要和 NameNode、SecondaryNameNode配置在同一台机器上</p><h2 id=准备配置文件>准备配置文件</h2><p>Hadoop准备了默认的配置文件：
<img src="https://img-blog.csdnimg.cn/20210602121020118.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzM5NDcyNA==,size_16,color_FFFFFF,t_70" alt=在这里插入图片描述>
可以作为参考
一般我们要自定义配置文件，要修改的配置文件在：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>$hadoop_home/etc/hadoop
</span></span></code></pre></div><p>实验环境：/opt/module/hadoop-3.1.3/etc/hadoop</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>[zyi@h102 hadoop-3.1.3]$ ll etc/hadoop/
</span></span><span style=display:flex><span>total 172
</span></span><span style=display:flex><span>......
</span></span><span style=display:flex><span>-rw-r--r--. 1 zyi zyi  1048 Jun  1 22:58 core-site.xml
</span></span><span style=display:flex><span>......
</span></span><span style=display:flex><span>-rw-r--r--. 1 zyi zyi  1036 Jun  1 22:57 hdfs-site.xml
</span></span><span style=display:flex><span>......
</span></span><span style=display:flex><span>-rw-r--r--. 1 zyi zyi   982 Jun  1 23:29 mapred-site.xml
</span></span><span style=display:flex><span>......
</span></span><span style=display:flex><span>-rw-r--r--. 1 zyi zyi  1304 Jun  1 23:24 yarn-site.xml
</span></span></code></pre></div><p>以上四个文件是需要修改的。</p><h3 id=core-sitexml-核心配置文件>core-site.xml 核心配置文件</h3><p>官方参考：<a href=https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/ClusterSetup.html#Configuring_the_Hadoop_Daemons>Configuring the Hadoop Daemons</a>
安装规划，我们指定h102为hdfs的namenode，对内port=8020</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>[zyi@h102 hadoop-3.1.3]$ cat ./etc/hadoop/core-site.xml
</span></span><span style=display:flex><span>&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;
</span></span><span style=display:flex><span>&lt;?xml-stylesheet type=&#34;text/xsl&#34; href=&#34;configuration.xsl&#34;?&gt;
</span></span><span style=display:flex><span>&lt;!--
</span></span><span style=display:flex><span>  Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
</span></span><span style=display:flex><span>  you may not use this file except in compliance with the License.
</span></span><span style=display:flex><span>  You may obtain a copy of the License at
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    http://www.apache.org/licenses/LICENSE-2.0
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  Unless required by applicable law or agreed to in writing, software
</span></span><span style=display:flex><span>  distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
</span></span><span style=display:flex><span>  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
</span></span><span style=display:flex><span>  See the License for the specific language governing permissions and
</span></span><span style=display:flex><span>  limitations under the License. See accompanying LICENSE file.
</span></span><span style=display:flex><span>--&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>&lt;!-- Put site-specific property overrides in this file. --&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>&lt;configuration&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  &lt;!-- file system properties --&gt;
</span></span><span style=display:flex><span>  &lt;property&gt;
</span></span><span style=display:flex><span>    &lt;name&gt;fs.defaultFS&lt;/name&gt;
</span></span><span style=display:flex><span>    &lt;value&gt;hdfs://h102:8020&lt;/value&gt;
</span></span><span style=display:flex><span>  &lt;/property&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  &lt;!--Foulder for hadoop data--&gt;
</span></span><span style=display:flex><span>  &lt;property&gt;
</span></span><span style=display:flex><span>    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
</span></span><span style=display:flex><span>    &lt;value&gt;/opt/module/hadoop-3.1.3/data&lt;/value&gt;
</span></span><span style=display:flex><span>  &lt;/property&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>&lt;/configuration&gt;
</span></span></code></pre></div><h3 id=hdfs配置文件>HDFS配置文件</h3><p>配置namenode对外的服务地址和端口以及2nn的部署（h104）</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>[zyi@h102 hadoop-3.1.3]$ cat ./etc/hadoop/hdfs-site.xml
</span></span><span style=display:flex><span>&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt;
</span></span><span style=display:flex><span>&lt;?xml-stylesheet type=&#34;text/xsl&#34; href=&#34;configuration.xsl&#34;?&gt;
</span></span><span style=display:flex><span>&lt;!--
</span></span><span style=display:flex><span>  Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
</span></span><span style=display:flex><span>  you may not use this file except in compliance with the License.
</span></span><span style=display:flex><span>  You may obtain a copy of the License at
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    http://www.apache.org/licenses/LICENSE-2.0
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  Unless required by applicable law or agreed to in writing, software
</span></span><span style=display:flex><span>  distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
</span></span><span style=display:flex><span>  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
</span></span><span style=display:flex><span>  See the License for the specific language governing permissions and
</span></span><span style=display:flex><span>  limitations under the License. See accompanying LICENSE file.
</span></span><span style=display:flex><span>--&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>&lt;!-- Put site-specific property overrides in this file. --&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>&lt;configuration&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  &lt;!--nn website addr--&gt;
</span></span><span style=display:flex><span>  &lt;property&gt;
</span></span><span style=display:flex><span>    &lt;name&gt;dfs.namenode.http-address&lt;/name&gt;
</span></span><span style=display:flex><span>    &lt;value&gt;h102:9870&lt;/value&gt;
</span></span><span style=display:flex><span>  &lt;/property&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  &lt;!--2nn website addr--&gt;
</span></span><span style=display:flex><span>  &lt;property&gt;
</span></span><span style=display:flex><span>    &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
</span></span><span style=display:flex><span>    &lt;value&gt;h104:9868&lt;/value&gt;
</span></span><span style=display:flex><span>  &lt;/property&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>&lt;/configuration&gt;
</span></span></code></pre></div><h3 id=yarn配置文件>Yarn配置文件</h3><p>指定resourcemanager的安装位置和方式，以及配置环境变量继承</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>[zyi@h102 hadoop-3.1.3]$ cat ./etc/hadoop/yarn-site.xml
</span></span><span style=display:flex><span>&lt;?xml version=&#34;1.0&#34;?&gt;
</span></span><span style=display:flex><span>&lt;!--
</span></span><span style=display:flex><span>  Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
</span></span><span style=display:flex><span>  you may not use this file except in compliance with the License.
</span></span><span style=display:flex><span>  You may obtain a copy of the License at
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    http://www.apache.org/licenses/LICENSE-2.0
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  Unless required by applicable law or agreed to in writing, software
</span></span><span style=display:flex><span>  distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
</span></span><span style=display:flex><span>  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
</span></span><span style=display:flex><span>  See the License for the specific language governing permissions and
</span></span><span style=display:flex><span>  limitations under the License. See accompanying LICENSE file.
</span></span><span style=display:flex><span>--&gt;
</span></span><span style=display:flex><span>&lt;configuration&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  &lt;property&gt;
</span></span><span style=display:flex><span>    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
</span></span><span style=display:flex><span>    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
</span></span><span style=display:flex><span>    &lt;!--RM use shuffle : &lt;value&gt;mapreduce_shuffle&lt;/value&gt;--&gt;
</span></span><span style=display:flex><span>  &lt;/property&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  &lt;property&gt;
</span></span><span style=display:flex><span>    &lt;description&gt;The hostname of the RM.&lt;/description&gt;
</span></span><span style=display:flex><span>    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
</span></span><span style=display:flex><span>    &lt;value&gt;h103&lt;/value&gt;
</span></span><span style=display:flex><span>  &lt;/property&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  &lt;property&gt;
</span></span><span style=display:flex><span>    &lt;description&gt;Environment variables that containers may override rather than use NodeManager&#39;s default.&lt;/description&gt;
</span></span><span style=display:flex><span>    &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;
</span></span><span style=display:flex><span>    &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt;
</span></span><span style=display:flex><span>  &lt;/property&gt;
</span></span><span style=display:flex><span>&lt;/configuration&gt;
</span></span></code></pre></div><h3 id=mapreduce配置文件>MapReduce配置文件</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>
</span></span><span style=display:flex><span>[zyi@h102 hadoop-3.1.3]$ cat ./etc/hadoop/mapred-site.xml
</span></span><span style=display:flex><span>&lt;?xml version=&#34;1.0&#34;?&gt;
</span></span><span style=display:flex><span>&lt;?xml-stylesheet type=&#34;text/xsl&#34; href=&#34;configuration.xsl&#34;?&gt;
</span></span><span style=display:flex><span>&lt;!--
</span></span><span style=display:flex><span>  Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
</span></span><span style=display:flex><span>  you may not use this file except in compliance with the License.
</span></span><span style=display:flex><span>  You may obtain a copy of the License at
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    http://www.apache.org/licenses/LICENSE-2.0
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  Unless required by applicable law or agreed to in writing, software
</span></span><span style=display:flex><span>  distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
</span></span><span style=display:flex><span>  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
</span></span><span style=display:flex><span>  See the License for the specific language governing permissions and
</span></span><span style=display:flex><span>  limitations under the License. See accompanying LICENSE file.
</span></span><span style=display:flex><span>--&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>&lt;!-- Put site-specific property overrides in this file. --&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>&lt;configuration&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  &lt;property&gt;
</span></span><span style=display:flex><span>    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
</span></span><span style=display:flex><span>    &lt;value&gt;yarn&lt;/value&gt;
</span></span><span style=display:flex><span>    &lt;description&gt;The runtime framework for executing MapReduce jobs.
</span></span><span style=display:flex><span>    Can be one of local, classic or yarn.
</span></span><span style=display:flex><span>    &lt;/description&gt;
</span></span><span style=display:flex><span>  &lt;/property&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>&lt;/configuration&gt;
</span></span></code></pre></div><h3 id=利用xsync发布给集群里的主机>利用xsync发布给集群里的主机</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>[zyi@h102 hadoop-3.1.3]$ cd etc/
</span></span><span style=display:flex><span>[zyi@h102 etc]$ xsync hadoop/
</span></span><span style=display:flex><span>==============================h102==============================
</span></span><span style=display:flex><span>sending incremental file list
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sent 878 bytes  received 18 bytes  358.40 bytes/sec
</span></span><span style=display:flex><span>total size is 107,612  speedup is 120.10
</span></span><span style=display:flex><span>==============================h103==============================
</span></span><span style=display:flex><span>sending incremental file list
</span></span><span style=display:flex><span>hadoop/
</span></span><span style=display:flex><span>hadoop/core-site.xml
</span></span><span style=display:flex><span>hadoop/hdfs-site.xml
</span></span><span style=display:flex><span>hadoop/mapred-site.xml
</span></span><span style=display:flex><span>hadoop/yarn-site.xml
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sent 3,339 bytes  received 139 bytes  2,318.67 bytes/sec
</span></span><span style=display:flex><span>total size is 107,612  speedup is 30.94
</span></span><span style=display:flex><span>==============================h104==============================
</span></span><span style=display:flex><span>sending incremental file list
</span></span><span style=display:flex><span>hadoop/
</span></span><span style=display:flex><span>hadoop/core-site.xml
</span></span><span style=display:flex><span>hadoop/hdfs-site.xml
</span></span><span style=display:flex><span>hadoop/mapred-site.xml
</span></span><span style=display:flex><span>hadoop/yarn-site.xml
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sent 3,339 bytes  received 139 bytes  2,318.67 bytes/sec
</span></span><span style=display:flex><span>total size is 107,612  speedup is 30.94
</span></span></code></pre></div><h3 id=修改workers文件>修改workers文件</h3><p>告诉hadoop集群有哪些主机参与</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>[zyi@h102 hadoop-3.1.3]$ vi /opt/module/hadoop-3.1.3/etc/hadoop/workers
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>h102
</span></span><span style=display:flex><span>h103
</span></span><span style=display:flex><span>h104
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>[zyi@h102 hadoop-3.1.3]$ xsync /opt/module/hadoop-3.1.3/etc/hadoop/   #同步
</span></span><span style=display:flex><span>==============================h102==============================
</span></span><span style=display:flex><span>sending incremental file list
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sent 887 bytes  received 18 bytes  1,810.00 bytes/sec
</span></span><span style=display:flex><span>total size is 107,617  speedup is 118.91
</span></span><span style=display:flex><span>==============================h103==============================
</span></span><span style=display:flex><span>sending incremental file list
</span></span><span style=display:flex><span>hadoop/
</span></span><span style=display:flex><span>hadoop/workers
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sent 952 bytes  received 46 bytes  665.33 bytes/sec
</span></span><span style=display:flex><span>total size is 107,617  speedup is 107.83
</span></span><span style=display:flex><span>==============================h104==============================
</span></span><span style=display:flex><span>sending incremental file list
</span></span><span style=display:flex><span>hadoop/
</span></span><span style=display:flex><span>hadoop/workers
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sent 952 bytes  received 46 bytes  1,996.00 bytes/sec
</span></span><span style=display:flex><span>total size is 107,617  speedup is 107.83
</span></span></code></pre></div><h2 id=启动集群>启动集群</h2><h3 id=初始化格式化namenode>初始化/格式化namenode</h3><p>注意 ：格式化 NameNode，会产生新的集群 id，导致 NameNode和 DataNode的集群id不一致，集群找不到已往数据。 如果集群在运行过程中报错，需要重新格式化，需要重新格式化 NameNode的话，一定要先停止 namenode和 datanode进程， 并且要 <strong>删除</strong> 所有机器的data和 logs目录，然后再进行格式。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>[zyi@h102 hadoop-3.1.3]$ hdfs namenode -format
</span></span><span style=display:flex><span>2021-06-02 05:01:45,180 INFO namenode.NameNode: STARTUP_MSG:
</span></span><span style=display:flex><span>/************************************************************
</span></span><span style=display:flex><span>STARTUP_MSG: Starting NameNode
</span></span><span style=display:flex><span>STARTUP_MSG:   host = h102/192.168.110.82
</span></span><span style=display:flex><span>STARTUP_MSG:   args = [-format]
</span></span><span style=display:flex><span>STARTUP_MSG:   version = 3.1.3
</span></span><span style=display:flex><span>STARTUP_MSG:   classpath = /opt/module/hadoop-3.1.3/etc/hadoop:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/asm-5.0.4.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/avro-1.7.7.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/commons-compress-1.18.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/commons-io-2.5.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/commons-lang3-3.4.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/commons-net-3.6.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/curator-client-2.13.0.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/curator-framework-2.13.0.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/gson-2.2.4.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/hadoop-annotations-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/hadoop-auth-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jackson-core-2.7.8.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jettison-1.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/json-smart-2.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/netty-3.10.5.Final.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/paranamer-2.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/re2j-1.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/zookeeper-3.4.13.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/hadoop-common-3.1.3-tests.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/hadoop-common-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/hadoop-nfs-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/common/hadoop-kms-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/hadoop-auth-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/hadoop-annotations-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/hadoop-hdfs-3.1.3-tests.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/hadoop-hdfs-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/hadoop-hdfs-client-3.1.3-tests.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/hadoop-hdfs-client-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.3-tests.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.3-tests.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.3-tests.jar:/opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn:/opt/module/hadoop-3.1.3/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/lib/fst-2.50.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/lib/guice-4.0.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/hadoop-yarn-api-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/hadoop-yarn-client-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/hadoop-yarn-common-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/hadoop-yarn-registry-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/hadoop-yarn-server-common-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/hadoop-yarn-server-router-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/hadoop-yarn-services-api-3.1.3.jar:/opt/module/hadoop-3.1.3/share/hadoop/yarn/hadoop-yarn-services-core-3.1.3.jar
</span></span><span style=display:flex><span>STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r ba631c436b806728f8ec2f54ab1e289526c90579; compiled by &#39;ztang&#39; on 2019-09-12T02:47Z
</span></span><span style=display:flex><span>STARTUP_MSG:   java = 1.8.0_212
</span></span><span style=display:flex><span>************************************************************/
</span></span><span style=display:flex><span>2021-06-02 05:01:45,195 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
</span></span><span style=display:flex><span>2021-06-02 05:01:45,466 INFO namenode.NameNode: createNameNode [-format]
</span></span><span style=display:flex><span>Formatting using clusterid: CID-19932890-94da-4efb-8d46-f8f1b85efc3c
</span></span><span style=display:flex><span>2021-06-02 05:01:47,460 INFO namenode.FSEditLog: Edit logging is async:true
</span></span><span style=display:flex><span>2021-06-02 05:01:47,533 INFO namenode.FSNamesystem: KeyProvider: null
</span></span><span style=display:flex><span>2021-06-02 05:01:47,537 INFO namenode.FSNamesystem: fsLock is fair: true
</span></span><span style=display:flex><span>2021-06-02 05:01:47,537 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
</span></span><span style=display:flex><span>2021-06-02 05:01:47,566 INFO namenode.FSNamesystem: fsOwner             = zyi (auth:SIMPLE)
</span></span><span style=display:flex><span>2021-06-02 05:01:47,567 INFO namenode.FSNamesystem: supergroup          = supergroup
</span></span><span style=display:flex><span>2021-06-02 05:01:47,567 INFO namenode.FSNamesystem: isPermissionEnabled = true
</span></span><span style=display:flex><span>2021-06-02 05:01:47,567 INFO namenode.FSNamesystem: HA Enabled: false
</span></span><span style=display:flex><span>2021-06-02 05:01:47,799 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
</span></span><span style=display:flex><span>2021-06-02 05:01:47,901 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
</span></span><span style=display:flex><span>2021-06-02 05:01:47,968 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
</span></span><span style=display:flex><span>2021-06-02 05:01:47,975 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
</span></span><span style=display:flex><span>2021-06-02 05:01:47,976 INFO blockmanagement.BlockManager: The block deletion will start around 2021 Jun 02 05:01:47
</span></span><span style=display:flex><span>2021-06-02 05:01:47,978 INFO util.GSet: Computing capacity for map BlocksMap
</span></span><span style=display:flex><span>2021-06-02 05:01:47,979 INFO util.GSet: VM type       = 64-bit
</span></span><span style=display:flex><span>2021-06-02 05:01:47,980 INFO util.GSet: 2.0% max memory 1.7 GB = 34.8 MB
</span></span><span style=display:flex><span>2021-06-02 05:01:47,980 INFO util.GSet: capacity      = 2^22 = 4194304 entries
</span></span><span style=display:flex><span>2021-06-02 05:01:48,393 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false
</span></span><span style=display:flex><span>2021-06-02 05:01:48,408 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
</span></span><span style=display:flex><span>2021-06-02 05:01:48,408 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
</span></span><span style=display:flex><span>2021-06-02 05:01:48,408 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
</span></span><span style=display:flex><span>2021-06-02 05:01:48,409 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
</span></span><span style=display:flex><span>2021-06-02 05:01:48,410 INFO blockmanagement.BlockManager: defaultReplication         = 3
</span></span><span style=display:flex><span>2021-06-02 05:01:48,410 INFO blockmanagement.BlockManager: maxReplication             = 512
</span></span><span style=display:flex><span>2021-06-02 05:01:48,410 INFO blockmanagement.BlockManager: minReplication             = 1
</span></span><span style=display:flex><span>2021-06-02 05:01:48,410 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
</span></span><span style=display:flex><span>2021-06-02 05:01:48,410 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
</span></span><span style=display:flex><span>2021-06-02 05:01:48,410 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
</span></span><span style=display:flex><span>2021-06-02 05:01:48,410 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
</span></span><span style=display:flex><span>2021-06-02 05:01:48,963 INFO namenode.FSDirectory: GLOBAL serial map: bits=24 maxEntries=16777215
</span></span><span style=display:flex><span>2021-06-02 05:01:49,164 INFO util.GSet: Computing capacity for map INodeMap
</span></span><span style=display:flex><span>2021-06-02 05:01:49,164 INFO util.GSet: VM type       = 64-bit
</span></span><span style=display:flex><span>2021-06-02 05:01:49,165 INFO util.GSet: 1.0% max memory 1.7 GB = 17.4 MB
</span></span><span style=display:flex><span>2021-06-02 05:01:49,165 INFO util.GSet: capacity      = 2^21 = 2097152 entries
</span></span><span style=display:flex><span>2021-06-02 05:01:49,915 INFO namenode.FSDirectory: ACLs enabled? false
</span></span><span style=display:flex><span>2021-06-02 05:01:49,916 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true
</span></span><span style=display:flex><span>2021-06-02 05:01:49,916 INFO namenode.FSDirectory: XAttrs enabled? true
</span></span><span style=display:flex><span>2021-06-02 05:01:49,916 INFO namenode.NameNode: Caching file names occurring more than 10 times
</span></span><span style=display:flex><span>2021-06-02 05:01:49,944 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
</span></span><span style=display:flex><span>2021-06-02 05:01:49,952 INFO snapshot.SnapshotManager: SkipList is disabled
</span></span><span style=display:flex><span>2021-06-02 05:01:49,978 INFO util.GSet: Computing capacity for map cachedBlocks
</span></span><span style=display:flex><span>2021-06-02 05:01:49,978 INFO util.GSet: VM type       = 64-bit
</span></span><span style=display:flex><span>2021-06-02 05:01:49,978 INFO util.GSet: 0.25% max memory 1.7 GB = 4.3 MB
</span></span><span style=display:flex><span>2021-06-02 05:01:49,979 INFO util.GSet: capacity      = 2^19 = 524288 entries
</span></span><span style=display:flex><span>2021-06-02 05:01:50,010 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
</span></span><span style=display:flex><span>2021-06-02 05:01:50,011 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
</span></span><span style=display:flex><span>2021-06-02 05:01:50,011 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
</span></span><span style=display:flex><span>2021-06-02 05:01:50,028 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
</span></span><span style=display:flex><span>2021-06-02 05:01:50,028 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
</span></span><span style=display:flex><span>2021-06-02 05:01:50,048 INFO util.GSet: Computing capacity for map NameNodeRetryCache
</span></span><span style=display:flex><span>2021-06-02 05:01:50,048 INFO util.GSet: VM type       = 64-bit
</span></span><span style=display:flex><span>2021-06-02 05:01:50,048 INFO util.GSet: 0.029999999329447746% max memory 1.7 GB = 534.2 KB
</span></span><span style=display:flex><span>2021-06-02 05:01:50,048 INFO util.GSet: capacity      = 2^16 = 65536 entries
</span></span><span style=display:flex><span>2021-06-02 05:01:50,140 INFO namenode.FSImage: Allocated new BlockPoolId: BP-847004710-192.168.110.82-1622624510113
</span></span><span style=display:flex><span>2021-06-02 05:01:50,217 INFO common.Storage: Storage directory /opt/module/hadoop-3.1.3/data/dfs/name has been successfully formatted.
</span></span><span style=display:flex><span>2021-06-02 05:01:50,274 INFO namenode.FSImageFormatProtobuf: Saving image file /opt/module/hadoop-3.1.3/data/dfs/name/current/fsimage.ckpt_0000000000000000000 using no compression
</span></span><span style=display:flex><span>2021-06-02 05:01:50,576 INFO namenode.FSImageFormatProtobuf: Image file /opt/module/hadoop-3.1.3/data/dfs/name/current/fsimage.ckpt_0000000000000000000 of size 390 bytes saved in 0 seconds .
</span></span><span style=display:flex><span>2021-06-02 05:01:50,620 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &gt;= 0
</span></span><span style=display:flex><span>2021-06-02 05:01:50,637 INFO namenode.FSImage: FSImageSaver clean checkpoint: txid = 0 when meet shutdown.
</span></span><span style=display:flex><span>2021-06-02 05:01:50,637 INFO namenode.NameNode: SHUTDOWN_MSG:
</span></span><span style=display:flex><span>/************************************************************
</span></span><span style=display:flex><span>SHUTDOWN_MSG: Shutting down NameNode at h102/192.168.110.82
</span></span><span style=display:flex><span>************************************************************/
</span></span></code></pre></div><p>完成以后在hadoop文件夹里生成了data和logs文件夹。
查看data文件夹</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>[zyi@h102 hadoop-3.1.3]$ ls
</span></span><span style=display:flex><span>bin  data  etc  include  input  lib  libexec  LICENSE.txt  logs  NOTICE.txt  output  README.txt  sbin  share
</span></span><span style=display:flex><span>[zyi@h102 hadoop-3.1.3]$ cd data/dfs/name/current/
</span></span><span style=display:flex><span>[zyi@h102 current]$ ll
</span></span><span style=display:flex><span>total 16
</span></span><span style=display:flex><span>-rw-rw-r--. 1 zyi zyi 390 Jun  2 05:04 fsimage_0000000000000000000
</span></span><span style=display:flex><span>-rw-rw-r--. 1 zyi zyi  62 Jun  2 05:04 fsimage_0000000000000000000.md5
</span></span><span style=display:flex><span>-rw-rw-r--. 1 zyi zyi   2 Jun  2 05:04 seen_txid
</span></span><span style=display:flex><span>-rw-rw-r--. 1 zyi zyi 218 Jun  2 05:04 VERSION
</span></span></code></pre></div><p>查看VERSION文件</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>[zyi@h102 current]$ cat VERSION
</span></span><span style=display:flex><span>#Wed Jun 02 05:04:26 EDT 2021
</span></span><span style=display:flex><span>namespaceID=632455869
</span></span><span style=display:flex><span>clusterID=CID-fd675fc9-998e-44d4-84f9-baa472f33d21
</span></span><span style=display:flex><span>cTime=1622624666933
</span></span><span style=display:flex><span>storageType=NAME_NODE
</span></span><span style=display:flex><span>blockpoolID=BP-1568640629-192.168.110.82-1622624666933
</span></span><span style=display:flex><span>layoutVersion=-64
</span></span></code></pre></div><h3 id=启动hdfs>启动HDFS</h3><p>启动的脚本在sbin目录下</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>[zyi@h102 current]$ cd /opt/module/hadoop-3.1.3/sbin/
</span></span><span style=display:flex><span>[zyi@h102 sbin]$ ls
</span></span><span style=display:flex><span>distribute-exclude.sh  httpfs.sh                start-all.cmd      start-dfs.sh         stop-all.cmd      stop-dfs.sh         workers.sh
</span></span><span style=display:flex><span>FederationStateStore   kms.sh                   start-all.sh       start-secure-dns.sh  stop-all.sh       stop-secure-dns.sh  yarn-daemon.sh
</span></span><span style=display:flex><span>hadoop-daemon.sh       mr-jobhistory-daemon.sh  start-balancer.sh  start-yarn.cmd       stop-balancer.sh  stop-yarn.cmd       yarn-daemons.sh
</span></span><span style=display:flex><span>hadoop-daemons.sh      refresh-namenodes.sh     start-dfs.cmd      start-yarn.sh        stop-dfs.cmd      stop-yarn.sh
</span></span><span style=display:flex><span>[zyi@h102 sbin]$ start-dfs.sh
</span></span><span style=display:flex><span>Starting namenodes on [h102]
</span></span><span style=display:flex><span>Starting datanodes
</span></span><span style=display:flex><span>h103: WARNING: /opt/module/hadoop-3.1.3/logs does not exist. Creating.
</span></span><span style=display:flex><span>h104: WARNING: /opt/module/hadoop-3.1.3/logs does not exist. Creating.
</span></span><span style=display:flex><span>Starting secondary namenodes [h104]
</span></span></code></pre></div><p>查看各主机的安装情况，对照设计</p><table><thead><tr><th>&ndash;</th><th>Hadoop102</th><th>Hadoop103</th><th>Hadoop104</th></tr></thead><tbody><tr><td>HDFS</td><td><strong>NameNode</strong> DataNode</td><td>DataNode</td><td><strong>SecondaryNameNode</strong> DataNode</td></tr></tbody></table><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>[zyi@h102 sbin]$ jps
</span></span><span style=display:flex><span>19681 NameNode
</span></span><span style=display:flex><span>20090 Jps
</span></span><span style=display:flex><span>19821 DataNode
</span></span><span style=display:flex><span>[zyi@h102 sbin]$ h103
</span></span><span style=display:flex><span>bash: h103: command not found...
</span></span><span style=display:flex><span>[zyi@h102 sbin]$ ssh h103
</span></span><span style=display:flex><span>Last login: Tue Jun  1 23:32:00 2021 from h102
</span></span><span style=display:flex><span>[zyi@h103 ~]$ jps
</span></span><span style=display:flex><span>25846 Jps
</span></span><span style=display:flex><span>25706 DataNode
</span></span><span style=display:flex><span>[zyi@h103 ~]$ exit
</span></span><span style=display:flex><span>logout
</span></span><span style=display:flex><span>Connection to h103 closed.
</span></span><span style=display:flex><span>[zyi@h102 sbin]$ ssh h104
</span></span><span style=display:flex><span>Last login: Tue Jun  1 22:47:39 2021 from h102
</span></span><span style=display:flex><span>[zyi@h104 ~]$ jps
</span></span><span style=display:flex><span>25092 DataNode
</span></span><span style=display:flex><span>25332 Jps
</span></span><span style=display:flex><span>25206 SecondaryNameNode
</span></span><span style=display:flex><span>[zyi@h104 ~]$
</span></span></code></pre></div><h3 id=启动yarn>启动Yarn</h3><p>注意需要在规划运行RM的主机上启动Yarn</p><table><thead><tr><th>&ndash;</th><th>Hadoop102</th><th>Hadoop103</th><th>Hadoop104</th></tr></thead><tbody><tr><td>HDFS</td><td><strong>NameNode</strong> DataNode</td><td>DataNode</td><td><strong>SecondaryNameNode</strong> DataNode</td></tr><tr><td>YARN</td><td>NodeManager</td><td><strong>ResourceManager</strong> NodeManager</td><td>NodeManager</td></tr></tbody></table><p>所以我们需要在h103上面启动Yarn</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>[zyi@h102 sbin]$ ssh h103
</span></span><span style=display:flex><span>Last login: Wed Jun  2 05:13:13 2021 from h102
</span></span><span style=display:flex><span>[zyi@h103 ~]$ cd /opt/module/hadoop-3.1.3/sbin/
</span></span><span style=display:flex><span>[zyi@h103 sbin]$ ls
</span></span><span style=display:flex><span>distribute-exclude.sh  httpfs.sh                start-all.cmd      start-dfs.sh         stop-all.cmd      stop-dfs.sh         workers.sh
</span></span><span style=display:flex><span>FederationStateStore   kms.sh                   start-all.sh       start-secure-dns.sh  stop-all.sh       stop-secure-dns.sh  yarn-daemon.sh
</span></span><span style=display:flex><span>hadoop-daemon.sh       mr-jobhistory-daemon.sh  start-balancer.sh  start-yarn.cmd       stop-balancer.sh  stop-yarn.cmd       yarn-daemons.sh
</span></span><span style=display:flex><span>hadoop-daemons.sh      refresh-namenodes.sh     start-dfs.cmd      start-yarn.sh        stop-dfs.cmd      stop-yarn.sh
</span></span><span style=display:flex><span>[zyi@h103 sbin]$ start-yarn.sh
</span></span><span style=display:flex><span>Starting resourcemanager
</span></span><span style=display:flex><span>Starting nodemanagers
</span></span></code></pre></div><p>查看安装结果，对比设计表</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>
</span></span><span style=display:flex><span>[zyi@h103 sbin]$ jps
</span></span><span style=display:flex><span>26679 ResourceManager
</span></span><span style=display:flex><span>25706 DataNode
</span></span><span style=display:flex><span>26798 NodeManager
</span></span><span style=display:flex><span>27183 Jps
</span></span><span style=display:flex><span>[zyi@h103 sbin]$ exit
</span></span><span style=display:flex><span>logout
</span></span><span style=display:flex><span>Connection to h103 closed.
</span></span><span style=display:flex><span>[zyi@h102 sbin]$ jps
</span></span><span style=display:flex><span>19681 NameNode
</span></span><span style=display:flex><span>20772 NodeManager
</span></span><span style=display:flex><span>20917 Jps
</span></span><span style=display:flex><span>19821 DataNode
</span></span><span style=display:flex><span>[zyi@h102 sbin]$ ssh h104
</span></span><span style=display:flex><span>Last login: Wed Jun  2 05:12:43 2021 from h102
</span></span><span style=display:flex><span>j[zyi@h104 ~]$ jps
</span></span><span style=display:flex><span>25092 DataNode
</span></span><span style=display:flex><span>25206 SecondaryNameNode
</span></span><span style=display:flex><span>26376 Jps
</span></span><span style=display:flex><span>26155 NodeManager
</span></span></code></pre></div><p>这样一个三台主机的hadoop集群就启动了。</p><h2 id=web查看>Web查看</h2><p>Hadoop自带HDFS和Yarn的web查看，地址为：
<img src="https://img-blog.csdnimg.cn/20210602194535875.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzM5NDcyNA==,size_16,color_FFFFFF,t_70" alt=在这里插入图片描述>
我们系统截图：
<img src="https://img-blog.csdnimg.cn/20210602194606904.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzM5NDcyNA==,size_16,color_FFFFFF,t_70" alt=在这里插入图片描述>
<img src="https://img-blog.csdnimg.cn/20210602194638689.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzM5NDcyNA==,size_16,color_FFFFFF,t_70" alt=在这里插入图片描述>
以上。</p></div><footer class=post-footer><div id=wcomments></div></footer></article></section></div></div><div class=sidebar-toggle><div class=sidebar-toggle-line-wrap><span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
<span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
<span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id=sidebar class=sidebar><div class=sidebar-inner><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target=post-toc-wrap>文章目录</li><li class=sidebar-nav-overview data-target=site-overview>站点概览</li></ul><section class="site-overview sidebar-panel"><div class="site-author motion-element" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image src=/img/avatar.png alt=Etaon><p class=site-author-name itemprop=name>Etaon</p><p class="site-description motion-element" itemprop=description>Kepp Going!</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href=/post/><span class=site-state-item-count>79</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>15</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>43</span>
<span class=site-state-item-name>标签</span></a></div></nav><div class="links-of-author motion-element"><span class=links-of-author-item><a href=https://github.com/etaon target=_blank title=GitHub><i class="fa fa-fw fa-github"></i>
GitHub</a></span>
<span class=links-of-author-item><a href=https://blog.csdn.net/weixin_43394724 target=_blank title=CSDN><i class="fa fa-fw fa-CSDN"></i>
CSDN</a></span></div><div class="links-of-blogroll motion-element links-of-blogroll-inline"><div class=links-of-blogroll-title><i class="fa fa-fw fa-globe"></i>
友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://kubernetes.io/ title=Kubernetes target=_blank>Kubernetes</a></li><li class=links-of-blogroll-item><a href=https://cisco.com/ title=Cisco target=_blank>Cisco</a></li><li class=links-of-blogroll-item><a href=https://www.w3school.com.cn/ title=W3School target=_blank>W3School</a></li><li class=links-of-blogroll-item><a href=https://www.liaoxuefeng.com/ title=廖雪峰 target=_blank>廖雪峰</a></li></ul></div><div class="tagcloud-of-blogroll motion-element tagcloud-of-blogroll-inline"><div class=tagcloud-of-blogroll-title><i class="fa fa-fw fa-tags"></i>
标签云</div><ul class=tagcloud-of-blogroll-list><li class=tagcloud-of-blogroll-item><a href=/tags/mysql>Mysql</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/aws>Aws</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/dql>Dql</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/hadoop>Hadoop</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/kubernetes>Kubernetes</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/nsx-t>Nsx t</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/redis>Redis</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/azure>Azure</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/cicd>Cicd</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/git>Git</a></li></ul></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class=post-toc><div class=post-toc-content><nav id=TableOfContents><ul><li><a href=#前期准备>前期准备</a><ul><li><a href=#同步小技巧>同步小技巧</a></li></ul></li><li><a href=#集群规划>集群规划</a></li><li><a href=#准备配置文件>准备配置文件</a><ul><li><a href=#core-sitexml-核心配置文件>core-site.xml 核心配置文件</a></li><li><a href=#hdfs配置文件>HDFS配置文件</a></li><li><a href=#yarn配置文件>Yarn配置文件</a></li><li><a href=#mapreduce配置文件>MapReduce配置文件</a></li><li><a href=#利用xsync发布给集群里的主机>利用xsync发布给集群里的主机</a></li><li><a href=#修改workers文件>修改workers文件</a></li></ul></li><li><a href=#启动集群>启动集群</a><ul><li><a href=#初始化格式化namenode>初始化/格式化namenode</a></li><li><a href=#启动hdfs>启动HDFS</a></li><li><a href=#启动yarn>启动Yarn</a></li></ul></li><li><a href=#web查看>Web查看</a></li></ul></nav></div></div></section></div></aside></div></main><footer id=footer class=footer><div class=footer-inner><div class=copyright><span class=copyright-year>&copy; 2010 - 2023</span>
<span class=with-love><i class="fa fa-heart"></i></span>
<span class=copyright-author>路无止境！</span></div><div class=powered-info><span class=powered-by>Powered by - <a class=powered-link href=//gohugo.io target=_blank title=hugo>Hugo v0.101.0</a></span>
<span class=separator-line>/</span>
<span class=theme-info>Theme by - <a class=powered-link href=//github.com/elkan1788/hugo-theme-next target=_blank>NexT</a></span></div><div class=vistor-info><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script>
<span class=site-uv><i class="fa fa-user"></i>
<span class=busuanzi-value id=busuanzi_value_site_uv></span></span>
<span class=separator-line>/</span>
<span class=site-pv><i class="fa fa-eye"></i>
<span class=busuanzi-value id=busuanzi_value_site_pv></span></span></div><div class=license-info><span class=storage-info>Storage by
<a href=https://www.azure.com/ style=font-weight:700 target=_blank>Azure static web apps</a></span>
<span class=separator-line>/</span>
<span class=license-num><a href target=_blank></a></span></div></div></footer><div class=back-to-top><i class="fa fa-arrow-up"></i>
<span id=scrollpercent><span>0</span>%</span></div></div><script type=text/javascript src=//cdn.bootcdn.net/ajax/libs/jquery/2.1.4/jquery.min.js></script>
<script type=text/javascript src=/js/search.js></script>
<script type=text/javascript src=/js/affix.js></script>
<script type=text/javascript src=/js/scrollspy.js></script>
<script type=text/javascript>function detectIE(){var e=window.navigator.userAgent,t=e.indexOf("MSIE "),n=e.indexOf("Trident/"),s=e.indexOf("Edge/");return t>0||n>0||s>0?-1:1}function getCntViewHeight(){var t=$("#content").height(),e=$(window).height(),n=t>e?t-e:$(document).height()-e;return n}function getScrollbarWidth(){var e=$("<div />").addClass("scrollbar-measure").prependTo("body"),t=e[0],n=t.offsetWidth-t.clientWidth;return e.remove(),n}function registerBackTop(){var t=50,e=$(".back-to-top");$(window).on("scroll",function(){e.toggleClass("back-to-top-on",window.pageYOffset>t);var s=$(window).scrollTop(),o=getCntViewHeight(),i=s/o,n=Math.round(i*100),a=n>100?100:n;$("#scrollpercent>span").html(a)}),e.on("click",function(){$("html,body").animate({scrollTop:0,screenLeft:0},800)})}function initScrollSpy(){var e=".post-toc",s=$(e),t=".active-current";s.on("activate.bs.scrollspy",function(){var t=$(e+" .active").last();n(),t.addClass("active-current")}).on("clear.bs.scrollspy",n),$("body").scrollspy({target:e});function n(){$(e+" "+t).removeClass(t.substring(1))}}function initAffix(){var e=$(".header-inner").height(),t=parseInt($(".main").css("padding-bottom"),10),n=e+10;$(".sidebar-inner").affix({offset:{top:n,bottom:t}}),$(document).on("affixed.bs.affix",function(){updateTOCHeight(document.body.clientHeight-100)})}function initTOCDimension(){$(window).on("resize",function(){e&&clearTimeout(e),e=setTimeout(function(){var e=document.body.clientHeight-100;updateTOCHeight(e)},0)}),updateTOCHeight(document.body.clientHeight-100);var e,t=getScrollbarWidth();$(".post-toc").css("width","calc(100% + "+t+"px)")}function updateTOCHeight(e){e=e||"auto",$(".post-toc").css("max-height",e)}$(function(){var e,t,n,s,o=$(".header-inner").height()+10;$("#sidebar").css({"margin-top":o}).show(),t=parseInt($("#sidebar").css("margin-top")),n=parseInt($(".sidebar-inner").css("height")),e=t+n,s=$(".content-wrap").height(),s<e&&$(".content-wrap").css("min-height",e),$(".site-nav-toggle").on("click",function(){var e=$(".site-nav"),o=$(".toggle"),t="site-nav-on",i="toggle-close",n=e.hasClass(t),a=n?"slideUp":"slideDown",s=n?"removeClass":"addClass";e.stop()[a]("normal",function(){e[s](t),o[s](i)})}),registerBackTop(),initScrollSpy(),initAffix(),initTOCDimension(),$(".sidebar-nav-toc").click(function(){$(this).addClass("sidebar-nav-active"),$(this).next().removeClass("sidebar-nav-active"),$("."+$(this).next().attr("data-target")).toggle(500),$("."+$(this).attr("data-target")).toggle(500)}),$(".sidebar-nav-overview").click(function(){$(this).addClass("sidebar-nav-active"),$(this).prev().removeClass("sidebar-nav-active"),$("."+$(this).prev().attr("data-target")).toggle(500),$("."+$(this).attr("data-target")).toggle(500)})})</script><script src=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.js></script>
<script type=text/javascript>$(function(){$(".post-body").viewer()})</script><script type=text/javascript>$(function(){detectIE()>0?$.getScript(document.location.protocol+"//cdn.jsdelivr.net/npm/@waline/client/dist/Waline.min.js",function(){new Waline({el:"#wcomments",visitor:!0,avatar:"wavatar",avatarCDN:"https://sdn.geekzu.org/avatar/",avatarForce:!1,wordLimit:"200",placeholder:" 欢迎留下您的宝贵建议，请填写您的昵称和邮箱便于后续交流. ^_^ ",requiredFields:["nick","mail"],serverURL:"Your WalineSerURL",lang:"zh-cn"})}):$("#wcomments").html("抱歉，Waline插件不支持IE或Edge，建议使用Chrome浏览器。")})</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_SVG"></script>
<script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=Your%20AddthisId"></script>
<script>(function(){var t,e=document.createElement("script"),n=window.location.protocol.split(":")[0];n==="https"?e.src="https://zz.bdstatic.com/linksubmit/push.js":e.src="http://push.zhanzhang.baidu.com/push.js",t=document.getElementsByTagName("script")[0],t.parentNode.insertBefore(e,t)})()</script></body></html>