<!doctype html><html lang=zh-cn dir=content/zh-cn>
<head>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge,chrome=1">
<meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1">
<meta http-equiv=content-security-policy content="upgrade-insecure-requests">
<title> Install Kubernetes 1.24 - 路无止境！ </title>
<meta name=keywords content="博客,架构师,思考,读书,笔记,技术,分享,云">
<meta name=author content="Etaon">
<meta property="og:title" content="Install Kubernetes 1.24">
<meta property="og:site_name" content="路无止境！">
<meta property="og:image" content="/img/author.jpg">
<meta name=title content="Install Kubernetes 1.24 - 路无止境！">
<meta name=description content="欢迎来到ETAON空间站，个人主要专注于Infra系统架构，私有/公有云产品，售前及微服务解决方案。">
<link rel="shortcut icon" href=/img/favicon.ico>
<link rel=apple-touch-icon href=/img/apple-touch-icon.png>
<link rel=apple-touch-icon-precomposed href=/img/apple-touch-icon.png>
<link href=//cdn.bootcdn.net/ajax/libs/font-awesome/4.6.2/css/font-awesome.min.css rel=stylesheet type=text/css>
<link href=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.css rel=stylesheet>
<link href=/css/main.css rel=stylesheet type=text/css>
<link href=/css/syntax.css rel=stylesheet type=text/css>
</head>
<body itemscope itemtype=http://schema.org/WebPage lang=zh-hans>
<div class="container one-collumn sidebar-position-left page-home">
<div class=headband></div>
<header id=header class=header itemscope itemtype=http://schema.org/WPHeader>
<div class=header-inner> <div class=site-brand-container>
<div class=site-nav-toggle>
<div class=toggle role=button style=opacity:1;top:0>
<span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span>
</div>
</div>
<div class=site-meta>
<div class=multi-lang-switch>
<i class="fa fa-fw fa-language" style=margin-right:5px></i>
<a class=lang-link id=zh-cn href=#>中文</a>
</div>
<div class=custom-logo-site-title>
<a href=/ class=brand rel=start>
<span class=logo-line-before><i></i></span>
<span class=site-title>路无止境！</span>
<span class=logo-line-after><i></i></span>
</a>
</div>
<p class=site-subtitle>没有伞的孩子要学会努力奔跑!</p>
</div>
<div class=site-nav-right>
<div class="toggle popup-trigger" style=opacity:1;top:0>
<i class="fa fa-search fa-fw fa-lg"></i>
</div>
</div>
</div>
<nav class=site-nav>
<ul id=menu class=menu>
<li class=menu-item>
<a href=/ rel=section>
<i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页
</a>
</li>
<li class=menu-item>
<a href=/post rel=section>
<i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档
</a>
</li>
<li class=menu-item>
<a href=/about.html rel=section>
<i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于我
</a>
</li>
<li class=menu-item>
<a href=/404.html rel=section>
<i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br>公益404
</a>
</li>
<li class="menu-item menu-item-search">
<a href=javascript:; class=popup-trigger> <i class="menu-item-icon fa fa-search fa-fw"></i> <br> 搜索</a>
</li>
</ul>
<div class=site-search>
<div class="popup search-popup local-search-popup">
<div class="local-search-header clearfix">
<span class=search-icon><i class="fa fa-search"></i> </span>
<span class=popup-btn-close><i class="fa fa-times-circle"></i></span>
<div class=local-search-input-wrapper>
<input autocomplete=off placeholder=搜索关键字... spellcheck=false type=text id=local-search-input autocapitalize=none autocorrect=off>
</div>
</div>
<div id=local-search-result></div>
</div>
</div>
</nav>
</div>
</header>
<main id=main class=main>
<div class=main-inner>
<div class=content-wrap>
<div id=content class=content>
<section id=posts class=posts-expand>
<article class="post post-type-normal" itemscope itemtype=http://schema.org/Article>
<header class=post-header>
<h1 class=post-title itemprop="name headline" style=font-weight:700>
<a class=post-title-link href=https://www.etaon.link/2022/06/6/Install-Kubernetes-1.24.html itemprop=url>
Install Kubernetes 1.24
</a>
</h1>
</header>
<div class=post-body itemprop=articleBody>
<h1 id=kubernetes容器运行时演进>Kubernetes容器运行时演进</h1>
<p>早期的kubernetes runtime架构，远没这么复杂，kubelet创建容器，直接调用docker daemon，docker daemon自己调用libcontainer就把容器运行起来。</p>
<p>国际大厂们认为运行时标准不能被 Docker 一家公司控制，于是就串通搞了开放容器标准 OCI。忽悠Docker 把 libcontainer 封装了一下，变成 runC 捐献出来作为 OCI 的参考实现。</p>
<blockquote>
<p>OCI（开放容器标准），规定了2点：</p>
<ul>
<li>容器镜像要长啥样，即 ImageSpec。里面的大致规定就是你这个东西需要是一个压缩了的文件夹，文件夹里以 xxx 结构放 xxx 文件；</li>
<li>容器要需要能接收哪些指令，这些指令的行为是什么，即 RuntimeSpec。这里面的大致内容就是“容器”要能够执行 “create”，“start”，“stop”，“delete” 这些命令，并且行为要规范。</li>
</ul>
<p>runC 参考实现，就是它能按照标准将符合标准的容器镜像运行起来，标准的好处就是方便搞创新，只要符合标准，生态圈里的其它工具都能和我一起工作（……当然 OCI 这个标准本身制定得不怎么样，真正工程上还是要做一些 adapter 的），那我的镜像就可以用任意的工具去构建，我的“容器”就不一定非要用 namespace 和 cgroups 来做隔离。这就让各种虚拟化容器可以更好地参与到容器实现当中。</p>
</blockquote>
<p>再接下来 rkt(coreos推出的，类似docker) 想从 Docker 那边分一杯羹，希望 Kubernetes 原生支持 rkt 作为运行时，而且 PR 还真的合进去了。但是，整合出现的很多坑让Kubernetes疲于奔命。</p>
<p>然后，在Kubernetes 1.5 推出了 CRI 机制，即容器运行时接口（Container Runtime Interface），Kubernetes 告诉大家，你们想做 Runtime 可以啊，实现这个接口就成，成功反客为主。</p>
<p>不过 ，当时的 Kubernetes 尚未达到如今这般武林盟主的地位，容器运行时当然不能说我跟 Kubernetes 绑死了只提供 CRI 接口，于是就有了 shim（垫片）这个说法，一个 shim 的职责就是作为 Adapter 将各种容器运行时本身的接口适配到 Kubernetes 的 CRI 接口上，如下图中dockershim。</p>
<p><img src=Install%20Kubernetes%201%2024%2037fb7d18c6e84cc7a8935f77e898cc40/Untitled.png alt=Untitled></p>
<p>这时，Docker 要搞 Swarm 进军 PaaS 市场，于是做了个架构切分，把容器操作都移动到一个单独的 Daemon 进程 containerd 中去，让 Docker Daemon 专门负责上层的封装编排。可惜 Swarm 在 Kubernetes 面前惨败。</p>
<p>之后，Docker 公司就把 containerd 项目捐给 CNCF 缩回去安心搞 Docker 企业版了。</p>
<p>Docker+containerd的runtime 实在是有点复杂了，于是Kubernetes就有了直接拿 containerd 做 oci-runtime 的方案。当然，除了 Kubernetes 之外，containerd 还要接诸如 Swarm 等调度系统，因此它不会去直接实现 CRI，这个适配工作当然就要交给一个 shim 了。</p>
<p>containerd 1.0 中，对 CRI 的适配通过一个单独的进程 CRI-containerd 来完成；</p>
<p>containerd 1.1 中做的又更漂亮一点，砍掉了 CRI-containerd 这个进程，直接把适配逻辑作为插件放进了 containerd 主进程中。</p>
<p>但在 containerd 做这些事情前，社区就已经有了一个更为专注的 cri-runtime：CRI-O，它非常纯粹，就是兼容 CRI 和 OCI，做一个 Kubernetes 专用的运行时：</p>
<p><img src=Install%20Kubernetes%201%2024%2037fb7d18c6e84cc7a8935f77e898cc40/Untitled%201.png alt=Untitled></p>
<p>其中 conmon 就对应 containerd-shim，大体意图是一样的。</p>
<p>CRI-O 和（直接调用）containerd 的方案比起默认的 dockershim 确实简洁很多，但没啥生产环境的验证案例。直到不久前的1.24版本，Kubernetes终于不再原生支持Docker，以后的生产环境想必越来越多的containerd 的方案了。</p>
<h1 id=kubernetes-124-安装准备>Kubernetes 1.24 安装准备</h1>
<h2 id=概述>概述</h2>
<p>从上面的讲诉我们可以看到以下几种实现runtime的方式，其中kubelet直接调用Docker 管理器的方式现在1.24已经不支持了。</p>
<p><img src=Install%20Kubernetes%201%2024%2037fb7d18c6e84cc7a8935f77e898cc40/Untitled%202.png alt=Untitled></p>
<ul>
<li>集群创建方式1：Containerd
默认情况下，Kubernetes在创建集群的时候，使用的就是 Containerd方式。</li>
<li>集群创建方式2：Docker
Docker使用的普及率较高，虽然Kubernetes 1.24默认情况下废弃了kubelet对于Docker的支持，但是我们还可以借助于Mirantis维护的cri-dockerd插件方式来实现Kubernetes集群的创建。</li>
<li>集群创建方式3：CRI-O
CRI-O的方式是Kubernetes创建容器最直接的一种方式，在创建集群的时候，需要借助于cri-o插件的方式来实现Kubernetes集群的创建。</li>
</ul>
<p><strong>注意：后两种方式需要对Kubelet程序的启动参数进行改造</strong></p>
<p>下面就这三种方式来分别实现：</p>
<p>我们使用Linux Ubuntu 20.04作为主机OS，首先设定好apt 源</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#080;font-style:italic>#ali源</span>
deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse
deb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse
deb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse

<span style=color:#080;font-style:italic>#清华源</span>

<span style=color:#080;font-style:italic># 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释</span>
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse
<span style=color:#080;font-style:italic># deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse</span>
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse
<span style=color:#080;font-style:italic># deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse</span>
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse
<span style=color:#080;font-style:italic># deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse</span>
deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse
<span style=color:#080;font-style:italic># deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse</span>
</code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>apt update
</code></pre></div><h2 id=前置条件>前置条件</h2>
<p>在Kubernetes官方文档中，我们可以找到对环境的要求</p>
<p><a href=https://kubernetes.io/zh/docs/setup/production-environment/tools/kubeadm/install-kubeadm/>安装 kubeadm</a></p>
<h2 id=before-you-begin><strong>Before you begin</strong></h2>
<ul>
<li>一台兼容的 Linux 主机。Kubernetes 项目为基于 Debian 和 Red Hat 的 Linux 发行版以及一些不提供包管理器的发行版提供通用的指令</li>
<li>每台机器 2 GB 或更多的 RAM （如果少于这个数字将会影响你应用的运行内存)</li>
<li>2 CPU 核或更多</li>
<li>集群中的所有机器的网络彼此均能相互连接(公网和内网都可以)</li>
<li>节点之中不可以有重复的主机名、MAC 地址或 product_uuid。请参见<a href=https://kubernetes.io/zh/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#verify-mac-address>这里</a>了解更多详细信息。</li>
<li>开启机器上的某些端口。请参见<a href=https://kubernetes.io/zh/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#check-required-ports>这里</a> 了解更多详细信息。主要是6443端口，如下命令检查是否开启</li>
</ul>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>nc 127.0.0.1 <span style=color:#666>6443</span>
</code></pre></div><ul>
<li>
<p>禁用交换分区。为了保证 kubelet 正常工作，你 <strong>必须</strong> 禁用交换分区。</p>
</li>
<li>
<p><strong><strong>允许 iptables 检查桥接流量</strong></strong></p>
<ul>
<li>确保 <code>br_netfilter</code>模块被加载。这一操作可以通过运行 <code>lsmod | grep br_netfilter</code>来完成。若要显式加载该模块，可执行 <code>sudo modprobe br_netfilter</code></li>
<li>为了让你的 Linux 节点上的 iptables 能够正确地查看桥接流量，你需要确保在你的 <code>sysctl</code> 配置中将 <code>net.bridge.bridge-nf-call-iptables</code> 设置为 1。例如：</li>
</ul>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>cat <span style=color:#b44>&lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.conf
</span><span style=color:#b44>br_netfilter
</span><span style=color:#b44>EOF</span>

sudo modprobe overlay
sudo modprobe br_netfilter

cat <span style=color:#b44>&lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf
</span><span style=color:#b44>net.bridge.bridge-nf-call-ip6tables = 1
</span><span style=color:#b44>net.bridge.bridge-nf-call-iptables = 1
</span><span style=color:#b44>net.ipv4.ip_forward = 1
</span><span style=color:#b44>EOF</span>
sudo sysctl --system
</code></pre></div><p>检查br_netfilter</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@cp:~# modinfo br_netfilter
filename:       /lib/modules/5.4.0-113-generic/kernel/net/bridge/br_netfilter.ko
description:    Linux ethernet netfilter firewall bridge
author:         Bart De Schuymer &lt;bdschuym@pandora.be&gt;
author:         Lennert Buytenhek &lt;buytenh@gnu.org&gt;
license:        GPL
srcversion:     C662270B33245DF63170D07
depends:        bridge
retpoline:      Y
intree:         Y
name:           br_netfilter
vermagic:       5.4.0-113-generic SMP mod_unload modversions
sig_id:         PKCS#7
signer:         Build <span style=color:#a2f>time</span> autogenerated kernel key
sig_key:        6E:D3:96:DC:0A:DB:28:8D:E2:D1:37:5C:EA:E7:55:AD:E5:7E:DD:AA
sig_hashalgo:   sha512
signature:      72:D5:E8:E3:90:FC:1D:A6:EC:C9:21:0D:37:81:F9:20:7C:C6:29:85:
                C8:7A:61:17:1F:05:D1:2F:67:F7:0B:69:95:08:F1:71:0E:7C:3A:16:
                58:C5:C6:03:08:BD:3C:F2:CE:6D:AC:FA:9A:CC:3B:53:0C:F6:C0:A1:
                95:B3:B7:7F:2F:1C:CB:79:C0:3B:D0:8B:39:E6:1D:F0:94:EF:7F:0E:
                2D:DA:03:0A:9D:4C:AB:83:DB:E2:DE:EC:60:60:26:A7:CC:4E:D6:5E:
                74:10:22:E0:7E:13:23:AB:99:A0:A8:AB:66:87:5E:49:D9:B4:86:96:
                BF:02:F4:3D:D2:01:AE:CA:34:5B:53:D1:76:41:1C:02:8C:BE:B3:DA:
                D2:96:C3:15:01:76:25:71:81:44:C3:3E:1B:09:7E:F1:C5:3C:4F:9C:
                FA:E3:90:BF:53:E1:B5:9B:1F:62:68:06:AA:16:03:48:38:54:6D:18:
                72:2D:62:93:68:B3:4A:DC:6B:51:CE:E6:91:A1:19:12:43:0D:CF:87:
                43:FC:5D:86:CD:FF:C3:9E:9C:FF:D2:8F:EE:00:87:2F:08:79:51:F8:
                F3:F8:17:1C:86:52:E8:80:79:32:63:EC:3C:E2:AF:A5:F0:2B:BB:B2:
                56:7F:0A:0E:98:0D:E4:DF:8A:96:A1:53:3C:AE:E6:7F:07:B3:21:3A:
                22:78:2A:0D:C1:40:E7:CB:9A:9E:77:9C:71:4F:AC:8A:09:79:2A:05:
                BD:1A:AD:92:0E:65:50:FD:2E:EC:9F:60:46:D5:15:21:BC:1C:51:FD:
                EF:C9:CC:1C:AD:CD:49:49:C9:9C:B3:77:16:B3:A2:5D:BF:12:41:6F:
                3C:95:FD:2D:3F:BF:A6:AD:E4:62:E6:E9:63:C2:C1:67:27:41:05:18:
                46:CD:FA:99:5A:71:9A:9B:2D:6E:64:35:F6:67:1B:EA:D6:E4:17:A7:
                7D:22:AB:A0:7A:E0:08:BB:76:B6:AF:1C:57:59:41:F3:AD:56:89:D7:
                64:4A:B6:DD:76:6D:87:B1:CE:AD:1E:B2:C7:85:F0:85:80:79:0E:AE:
                5A:DF:EE:6E:43:9E:49:0A:64:A3:11:5A:2E:F9:7B:B4:A7:A1:88:C8:
                AC:FB:1B:2E:4B:1A:03:C8:42:31:9A:D1:4A:18:0F:FA:AA:D1:E4:79:
                75:2A:23:6C:4C:B3:8B:5A:CA:C2:29:BC:81:A1:91:8D:FC:41:1A:C2:
                AA:1F:2F:54:0D:D9:14:F1:CF:14:A8:44:CC:F5:4C:06:C8:DD:32:52:
                4B:48:00:32:3E:41:6E:F7:3F:BE:5B:48:33:04:10:02:B0:68:20:F6:
                2B:AD:08:6B:B8:D3:91:4A:A7:4D:79:F9
</code></pre></div><h2 id=软件部署>软件部署</h2>
<p>更新软件源</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>curl -s <span style=color:#666>[</span>https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg<span style=color:#666>](</span>https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg<span style=color:#666>)</span> | sudo apt-key add -
<span style=color:#a2f>echo</span> <span style=color:#b44>&#34;deb [https://mirrors.aliyun.com/kubernetes/apt/](https://mirrors.aliyun.com/kubernetes/apt/) kubernetes-xenial main&#34;</span> | sudo tee /etc/apt/sources.list.d/kubernetes.list
apt update

</code></pre></div><p>查看kubeadm的版本</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@cp:~# apt-cache madison kubeadm | head
   kubeadm |  1.24.1-00 | https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 Packages
   kubeadm |  1.24.0-00 | https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 Packages
   kubeadm |  1.23.7-00 | https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 Packages
   kubeadm |  1.23.6-00 | https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 Packages
   kubeadm |  1.23.5-00 | https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 Packages
   kubeadm |  1.23.4-00 | https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 Packages
   kubeadm |  1.23.3-00 | https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 Packages
   kubeadm |  1.23.2-00 | https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 Packages
   kubeadm |  1.23.1-00 | https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 Packages
   kubeadm |  1.23.0-00 | https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial/main amd64 Packages
</code></pre></div><p>安装软件</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>apt install -y <span style=color:#b8860b>kubeadm</span><span style=color:#666>=</span>1.24.1-00 <span style=color:#b8860b>kubelet</span><span style=color:#666>=</span>1.24.1-00 <span style=color:#b8860b>kubectl</span><span style=color:#666>=</span>1.24.1-00

<span style=color:#080;font-style:italic>#最新版本可用省略版本号</span>
注意：
会自动安装：
conntrack cri-tools ebtables ethtool kubernetes-cni socat

</code></pre></div><p>软件的的禁止更新</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>apt-mark hold kubelet kubeadm kubectl
注意：
apt-mark 可以对软件包设置标记
hold 标记指定软件包为保留（held back），阻止软件自动更新
</code></pre></div><p>安装好了以后kubelet由于没有底层容器运行时，service fail</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@cp:~# systemctl status kubelet
● kubelet.service - kubelet: The Kubernetes Node Agent
     Loaded: loaded <span style=color:#666>(</span>/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled<span style=color:#666>)</span>
    Drop-In: /etc/systemd/system/kubelet.service.d
             └─10-kubeadm.conf
     Active: activating <span style=color:#666>(</span>auto-restart<span style=color:#666>)</span> <span style=color:#666>(</span>Result: exit-code<span style=color:#666>)</span> since Wed 2022-06-01 03:37:39 UTC; 1s ago
       Docs: https://kubernetes.io/docs/home/
    Process: <span style=color:#666>8935</span> <span style=color:#b8860b>ExecStart</span><span style=color:#666>=</span>/usr/bin/kubelet <span style=color:#b8860b>$KUBELET_KUBECONFIG_ARGS</span> <span style=color:#b8860b>$KUBELET_CONFIG_ARGS</span> <span style=color:#b8860b>$KUBELET_KUBEADM_ARGS</span> <span style=color:#b8860b>$KUBELET_EXTRA_ARGS</span> <span style=color:#666>(</span><span style=color:#b8860b>code</span><span style=color:#666>=</span>exited, <span style=color:#b8860b>status</span><span style=color:#666>=</span>1/FAILURE<span style=color:#666>)</span>
   Main PID: <span style=color:#666>8935</span> <span style=color:#666>(</span><span style=color:#b8860b>code</span><span style=color:#666>=</span>exited, <span style=color:#b8860b>status</span><span style=color:#666>=</span>1/FAILURE<span style=color:#666>)</span>
</code></pre></div><p>自动生成一个配置文件：可改造</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@cp:~# cat /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
<span style=color:#080;font-style:italic># Note: This dropin only works with kubeadm and kubelet v1.11+</span>
<span style=color:#666>[</span>Service<span style=color:#666>]</span>
<span style=color:#b8860b>Environment</span><span style=color:#666>=</span><span style=color:#b44>&#34;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf&#34;</span>
<span style=color:#b8860b>Environment</span><span style=color:#666>=</span><span style=color:#b44>&#34;KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml&#34;</span>
<span style=color:#080;font-style:italic># This is a file that &#34;kubeadm init&#34; and &#34;kubeadm join&#34; generates at runtime, populating the KUBELET_KUBEADM_ARGS variable dynamically</span>
<span style=color:#b8860b>EnvironmentFile</span><span style=color:#666>=</span>-/var/lib/kubelet/kubeadm-flags.env
<span style=color:#080;font-style:italic># This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably, the user should use</span>
<span style=color:#080;font-style:italic># the .NodeRegistration.KubeletExtraArgs object in the configuration files instead. KUBELET_EXTRA_ARGS should be sourced from this file.</span>
<span style=color:#b8860b>EnvironmentFile</span><span style=color:#666>=</span>-/etc/default/kubelet
<span style=color:#b8860b>ExecStart</span><span style=color:#666>=</span>
<span style=color:#b8860b>ExecStart</span><span style=color:#666>=</span>/usr/bin/kubelet <span style=color:#b8860b>$KUBELET_KUBECONFIG_ARGS</span> <span style=color:#b8860b>$KUBELET_CONFIG_ARGS</span> <span style=color:#b8860b>$KUBELET_KUBEADM_ARGS</span> <span style=color:#b8860b>$KUBELET_EXTRA_ARGS</span>
</code></pre></div><p>查看底层容器的支持</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@cp:~# crictl images
WARN<span style=color:#666>[</span>0000<span style=color:#666>]</span> image connect using default endpoints: <span style=color:#666>[</span>unix:///var/run/dockershim.sock unix:///run/containerd/containerd.sock unix:///run/crio/crio.sock unix:///var/run/cri-dockerd.sock<span style=color:#666>]</span>. As the default settings are now deprecated, you should <span style=color:#a2f>set</span> the endpoint instead.
ERRO<span style=color:#666>[</span>0000<span style=color:#666>]</span> unable to determine image API version: rpc error: <span style=color:#b8860b>code</span> <span style=color:#666>=</span> Unavailable <span style=color:#b8860b>desc</span> <span style=color:#666>=</span> connection error: <span style=color:#b8860b>desc</span> <span style=color:#666>=</span> <span style=color:#b44>&#34;transport: Error while dialing dial unix /var/run/dockershim.sock: connect: no such file or directory&#34;</span>
ERRO<span style=color:#666>[</span>0000<span style=color:#666>]</span> unable to determine image API version: rpc error: <span style=color:#b8860b>code</span> <span style=color:#666>=</span> Unavailable <span style=color:#b8860b>desc</span> <span style=color:#666>=</span> connection error: <span style=color:#b8860b>desc</span> <span style=color:#666>=</span> <span style=color:#b44>&#34;transport: Error while dialing dial unix /run/containerd/containerd.sock: connect: no such file or directory&#34;</span>
ERRO<span style=color:#666>[</span>0000<span style=color:#666>]</span> unable to determine image API version: rpc error: <span style=color:#b8860b>code</span> <span style=color:#666>=</span> Unavailable <span style=color:#b8860b>desc</span> <span style=color:#666>=</span> connection error: <span style=color:#b8860b>desc</span> <span style=color:#666>=</span> <span style=color:#b44>&#34;transport: Error while dialing dial unix /run/crio/crio.sock: connect: no such file or directory&#34;</span>
ERRO<span style=color:#666>[</span>0000<span style=color:#666>]</span> unable to determine image API version: rpc error: <span style=color:#b8860b>code</span> <span style=color:#666>=</span> Unavailable <span style=color:#b8860b>desc</span> <span style=color:#666>=</span> connection error: <span style=color:#b8860b>desc</span> <span style=color:#666>=</span> <span style=color:#b44>&#34;transport: Error while dialing dial unix /var/run/cri-dockerd.sock: connect: no such file or directory&#34;</span>
FATA<span style=color:#666>[</span>0000<span style=color:#666>]</span> unable to determine image API version: rpc error: <span style=color:#b8860b>code</span> <span style=color:#666>=</span> Unavailable <span style=color:#b8860b>desc</span> <span style=color:#666>=</span> connection error: <span style=color:#b8860b>desc</span> <span style=color:#666>=</span> <span style=color:#b44>&#34;transport: Error while dialing dial unix /var/run/cri-dockerd.sock: connect: no such file or directory&#34;</span>
</code></pre></div><p>其中image connect using default endpoints:</p>
<ul>
<li>unix:///var/run/dockershim.sock #1.24本身不再支持</li>
<li>unix:///run/containerd/containerd.sock#官方默认</li>
<li>unix:///run/crio/crio.sock</li>
<li>unix:///var/run/cri-dockerd.sock].</li>
</ul>
<p>此时建议做快照！</p>
<h1 id=containerd方式创建集群>Containerd方式创建集群</h1>
<p><a href=https://kubernetes.io/zh/docs/setup/production-environment/container-runtimes/#containerd>容器运行时</a></p>
<p>该方法需要：</p>
<ol>
<li>安装Containerd</li>
<li>对Containerd进行配置</li>
<li>初始化集群并安装CNI</li>
</ol>
<h2 id=安装containerd>安装Containerd</h2>
<h3 id=在线安装方式>在线安装方式</h3>
<p>安装基础软件：</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@master:~# apt install -y curl gnupg2 software-properties-common apt-transport-https ca-certificates
</code></pre></div><p>安装containerd.io</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>
curl -fsSL https://download.docker.com/linux/ubuntu/gpg |sudo apt-key add -
add-apt-repository <span style=color:#b44>&#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu </span><span style=color:#a2f;font-weight:700>$(</span>lsb_release -cs<span style=color:#a2f;font-weight:700>)</span><span style=color:#b44> stable&#34;</span>
apt update
apt install-y containerd.io

</code></pre></div><p>查看安装containerd.io的结果</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@worker01:~# dpkg -L containerd.io
/.
/etc
/etc/containerd
/etc/containerd/config.toml
/lib
/lib/systemd
/lib/systemd/system
/lib/systemd/system/containerd.service
/usr
/usr/bin
/usr/bin/containerd
/usr/bin/containerd-shim
/usr/bin/containerd-shim-runc-v1
/usr/bin/containerd-shim-runc-v2
**/usr/bin/ctr
/usr/bin/runc**
/usr/share
/usr/share/doc
/usr/share/doc/containerd.io
/usr/share/doc/containerd.io/changelog.Debian.gz
/usr/share/doc/containerd.io/copyright
/usr/share/man
/usr/share/man/man5
/usr/share/man/man5/containerd-config.toml.5.gz
/usr/share/man/man8
/usr/share/man/man8/containerd-config.8.gz
/usr/share/man/man8/containerd.8.gz
/usr/share/man/man8/ctr.8.gz
</code></pre></div><p>Containerd的默认配置文件/etc/containerd/config.toml</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@worker01:~# cat /etc/containerd/config.toml
<span style=color:#080;font-style:italic>#   Copyright 2018-2022 Docker Inc.</span>

<span style=color:#080;font-style:italic>#   Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);</span>
<span style=color:#080;font-style:italic>#   you may not use this file except in compliance with the License.</span>
<span style=color:#080;font-style:italic>#   You may obtain a copy of the License at</span>

<span style=color:#080;font-style:italic>#       http://www.apache.org/licenses/LICENSE-2.0</span>

<span style=color:#080;font-style:italic>#   Unless required by applicable law or agreed to in writing, software</span>
<span style=color:#080;font-style:italic>#   distributed under the License is distributed on an &#34;AS IS&#34; BASIS,</span>
<span style=color:#080;font-style:italic>#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span style=color:#080;font-style:italic>#   See the License for the specific language governing permissions and</span>
<span style=color:#080;font-style:italic>#   limitations under the License.</span>

<span style=color:#b8860b>disabled_plugins</span> <span style=color:#666>=</span> <span style=color:#666>[</span><span style=color:#b44>&#34;cri&#34;</span><span style=color:#666>]</span>

<span style=color:#080;font-style:italic>#root = &#34;/var/lib/containerd&#34;</span>
<span style=color:#080;font-style:italic>#state = &#34;/run/containerd&#34;</span>
<span style=color:#080;font-style:italic>#subreaper = true</span>
<span style=color:#080;font-style:italic>#oom_score = 0</span>

<span style=color:#080;font-style:italic>#[grpc]</span>
<span style=color:#080;font-style:italic>#  address = &#34;/run/containerd/containerd.sock&#34;</span>
<span style=color:#080;font-style:italic>#  uid = 0</span>
<span style=color:#080;font-style:italic>#  gid = 0</span>

<span style=color:#080;font-style:italic>#[debug]</span>
<span style=color:#080;font-style:italic>#  address = &#34;/run/containerd/debug.sock&#34;</span>
<span style=color:#080;font-style:italic>#  uid = 0</span>
<span style=color:#080;font-style:italic>#  gid = 0</span>
<span style=color:#080;font-style:italic>#  level = &#34;info&#34;</span>
</code></pre></div><p>可以看到配置都被注释，默认的containerd的配置可以通过containerd config default查看:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@worker01:~# containerd config default
<span style=color:#b8860b>disabled_plugins</span> <span style=color:#666>=</span> <span style=color:#666>[]</span>
<span style=color:#b8860b>imports</span> <span style=color:#666>=</span> <span style=color:#666>[]</span>
<span style=color:#b8860b>oom_score</span> <span style=color:#666>=</span> <span style=color:#666>0</span>
<span style=color:#b8860b>plugin_dir</span> <span style=color:#666>=</span> <span style=color:#b44>&#34;&#34;</span>
<span style=color:#b8860b>required_plugins</span> <span style=color:#666>=</span> <span style=color:#666>[]</span>
<span style=color:#b8860b>root</span> <span style=color:#666>=</span> <span style=color:#b44>&#34;/var/lib/containerd&#34;</span>
<span style=color:#b8860b>state</span> <span style=color:#666>=</span> <span style=color:#b44>&#34;/run/containerd&#34;</span>
<span style=color:#b8860b>temp</span> <span style=color:#666>=</span> <span style=color:#b44>&#34;&#34;</span>
<span style=color:#b8860b>version</span> <span style=color:#666>=</span> <span style=color:#666>2</span>

<span style=color:#666>[</span>cgroup<span style=color:#666>]</span>
  <span style=color:#b8860b>path</span> <span style=color:#666>=</span> <span style=color:#b44>&#34;&#34;</span>

<span style=color:#666>[</span>debug<span style=color:#666>]</span>
  <span style=color:#b8860b>address</span> <span style=color:#666>=</span> <span style=color:#b44>&#34;&#34;</span>
  <span style=color:#b8860b>format</span> <span style=color:#666>=</span> <span style=color:#b44>&#34;&#34;</span>
  <span style=color:#b8860b>gid</span> <span style=color:#666>=</span> <span style=color:#666>0</span>
  <span style=color:#b8860b>level</span> <span style=color:#666>=</span> <span style=color:#b44>&#34;&#34;</span>
  <span style=color:#b8860b>uid</span> <span style=color:#666>=</span> <span style=color:#666>0</span>

......
<span style=color:#666>[</span>ttrpc<span style=color:#666>]</span>
  <span style=color:#b8860b>address</span> <span style=color:#666>=</span> <span style=color:#b44>&#34;&#34;</span>
  <span style=color:#b8860b>gid</span> <span style=color:#666>=</span> <span style=color:#666>0</span>
  <span style=color:#b8860b>uid</span> <span style=color:#666>=</span> <span style=color:#666>0</span>
</code></pre></div><p>为了修改kubernetes的源，接下来生成containerd的配置并修改（也可以修改kubelet的配置）</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#080;font-style:italic>#定制配置</span>
mkdir -p /etc/containerd
containerd config default | tee /etc/containerd/config.toml
</code></pre></div><p>直接修改：/etc/containerd/config.toml</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>    <span style=color:#b8860b>sandbox_image</span> <span style=color:#666>=</span> <span style=color:#b44>&#34;registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6&#34;</span>
...
<span style=color:#666>[</span>plugins.<span style=color:#b44>&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.runc.options<span style=color:#666>]</span>
            ...
            <span style=color:#b8860b>SystemdCgroup</span> <span style=color:#666>=</span> <span style=color:#a2f>true</span>

<span style=color:#080;font-style:italic>#注意修改SystemdCgroup</span>

<span style=color:#080;font-style:italic>#重启containerd</span>
systemctl restart containerd
</code></pre></div><p>Containerd提供了ctr命令来进行操作，如</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@cp:~# ctr image ls
REF TYPE DIGEST SIZE PLATFORMS LABELS
</code></pre></div><p>而kubernetes对ctr命令进行了封装，得到crictl命令（ctr tools）</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@cp:~# crictl images list
WARN<span style=color:#666>[</span>0000<span style=color:#666>]</span> image connect using default endpoints: <span style=color:#666>[</span>unix:///var/run/dockershim.sock unix:///run/containerd/containerd.sock unix:///run/crio/crio.sock unix:///var/run/cri-dockerd.sock<span style=color:#666>]</span>. As the default settings are now deprecated, you should <span style=color:#a2f>set</span> the endpoint instead.
ERRO<span style=color:#666>[</span>0000<span style=color:#666>]</span> unable to determine image API version: rpc error: <span style=color:#b8860b>code</span> <span style=color:#666>=</span> Unavailable <span style=color:#b8860b>desc</span> <span style=color:#666>=</span> connection error: <span style=color:#b8860b>desc</span> <span style=color:#666>=</span> <span style=color:#b44>&#34;transport: Error while dialing dial unix /var/run/dockershim.sock: connect: no such file or directory&#34;</span>
E0601 05:48:16.809106   <span style=color:#666>30961</span> remote_image.go:121<span style=color:#666>]</span> <span style=color:#b44>&#34;ListImages with filter from image service failed&#34;</span> <span style=color:#b8860b>err</span><span style=color:#666>=</span><span style=color:#b44>&#34;rpc error: code = Unimplemented desc = unknown service runtime.v1alpha2.ImageService&#34;</span> <span style=color:#b8860b>filter</span><span style=color:#666>=</span><span style=color:#b44>&#34;&amp;ImageFilter{Image:&amp;ImageSpec{Image:list,Annotations:map[string]string{},},}&#34;</span>
FATA<span style=color:#666>[</span>0000<span style=color:#666>]</span> listing images: rpc error: <span style=color:#b8860b>code</span> <span style=color:#666>=</span> Unimplemented <span style=color:#b8860b>desc</span> <span style=color:#666>=</span> unknown service runtime.v1alpha2.ImageService
</code></pre></div><p>这是由于没有运行时的入口，我们可以修改crictl配置文件，获得containerd的sock信息</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#080;font-style:italic>#cat /etc/crictl.yaml</span>
runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
timeout: <span style=color:#666>10</span>
debug: <span style=color:#a2f>false</span>

</code></pre></div><p>重启服务</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>systemctl restart containerd
systenctl <span style=color:#a2f>enable</span> containerd

root@cp:~# systemctl status containerd
● containerd.service - containerd container runtime
     Loaded: loaded <span style=color:#666>(</span>/lib/systemd/system/containerd.service; enabled; vendor preset: enabled<span style=color:#666>)</span>
     Active: active <span style=color:#666>(</span>running<span style=color:#666>)</span> since Wed 2022-06-01 05:52:04 UTC; 29s ago
       Docs: https://containerd.io
   Main PID: <span style=color:#666>31549</span> <span style=color:#666>(</span>containerd<span style=color:#666>)</span>
      Tasks: <span style=color:#666>10</span>
     Memory: 19.4M
     CGroup: /system.slice/containerd.service
             └─31549 /usr/bin/containerd

Jun <span style=color:#666>01</span> 05:52:04 cp containerd<span style=color:#666>[</span>31549<span style=color:#666>]</span>: <span style=color:#b8860b>time</span><span style=color:#666>=</span><span style=color:#b44>&#34;2022-06-01T05:52:04.079492081Z&#34;</span> <span style=color:#b8860b>level</span><span style=color:#666>=</span>info <span style=color:#b8860b>msg</span><span style=color:#666>=</span><span style=color:#b44>&#34;loading plugin \&#34;io.containerd.tracing.processor.v1.otlp\&#34;...&#34;</span> <span style=color:#b8860b>type</span><span style=color:#666>=</span>io.contai&gt;
Jun <span style=color:#666>01</span> 05:52:04 cp containerd<span style=color:#666>[</span>31549<span style=color:#666>]</span>: <span style=color:#b8860b>time</span><span style=color:#666>=</span><span style=color:#b44>&#34;2022-06-01T05:52:04.079513258Z&#34;</span> <span style=color:#b8860b>level</span><span style=color:#666>=</span>info <span style=color:#b8860b>msg</span><span style=color:#666>=</span><span style=color:#b44>&#34;skip loading plugin \&#34;io.containerd.tracing.processor.v1.otlp\&#34;...&#34;</span> <span style=color:#b8860b>error</span><span style=color:#666>=</span><span style=color:#b44>&#34;no&gt;
</span><span style=color:#b44>Jun 01 05:52:04 cp containerd[31549]: time=&#34;</span>2022-06-01T05:52:04.079524291Z<span style=color:#b44>&#34; level=info msg=&#34;</span>loading plugin <span style=color:#b62;font-weight:700>\&#34;</span>io.containerd.internal.v1.tracing<span style=color:#b62;font-weight:700>\&#34;</span>...<span style=color:#b44>&#34; type=io.containerd.i&gt;
</span><span style=color:#b44>Jun 01 05:52:04 cp containerd[31549]: time=&#34;</span>2022-06-01T05:52:04.079559919Z<span style=color:#b44>&#34; level=error msg=&#34;</span>failed to initialize a tracing processor <span style=color:#b62;font-weight:700>\&#34;</span>otlp<span style=color:#b62;font-weight:700>\&#34;</span><span style=color:#b44>&#34; error=&#34;</span>no OpenTelemetry e&gt;
Jun <span style=color:#666>01</span> 05:52:04 cp containerd<span style=color:#666>[</span>31549<span style=color:#666>]</span>: <span style=color:#b8860b>time</span><span style=color:#666>=</span><span style=color:#b44>&#34;2022-06-01T05:52:04.079597162Z&#34;</span> <span style=color:#b8860b>level</span><span style=color:#666>=</span>info <span style=color:#b8860b>msg</span><span style=color:#666>=</span><span style=color:#b44>&#34;loading plugin \&#34;io.containerd.grpc.v1.cri\&#34;...&#34;</span> <span style=color:#b8860b>type</span><span style=color:#666>=</span>io.containerd.grpc.v1
Jun <span style=color:#666>01</span> 05:52:04 cp containerd<span style=color:#666>[</span>31549<span style=color:#666>]</span>: <span style=color:#b8860b>time</span><span style=color:#666>=</span><span style=color:#b44>&#34;2022-06-01T05:52:04.079791605Z&#34;</span> <span style=color:#b8860b>level</span><span style=color:#666>=</span>warning <span style=color:#b8860b>msg</span><span style=color:#666>=</span><span style=color:#b44>&#34;failed to load plugin io.containerd.grpc.v1.cri&#34;</span> <span style=color:#b8860b>error</span><span style=color:#666>=</span><span style=color:#b44>&#34;invalid plugin con&gt;
</span><span style=color:#b44>Jun 01 05:52:04 cp containerd[31549]: time=&#34;</span>2022-06-01T05:52:04.080004161Z<span style=color:#b44>&#34; level=info msg=serving... address=/run/containerd/containerd.sock.ttrpc
</span><span style=color:#b44>Jun 01 05:52:04 cp containerd[31549]: time=&#34;</span>2022-06-01T05:52:04.080057668Z<span style=color:#b44>&#34; level=info msg=serving... address=/run/containerd/containerd.sock
</span><span style=color:#b44>Jun 01 05:52:04 cp systemd[1]: Started containerd container runtime.
</span><span style=color:#b44>Jun 01 05:52:04 cp containerd[31549]: time=&#34;</span>2022-06-01T05:52:04.081450178Z<span style=color:#b44>&#34; level=info msg=&#34;</span>containerd successfully booted in 0.030415s<span style=color:#b44>&#34;
</span></code></pre></div><h3 id=离线安装方式>离线安装方式</h3>
<p>需要下载runc和containerd</p>
<p><a href=https://github.com/opencontainers/runc>https://github.com/opencontainers/runc</a></p>
</li>
</ul>
<p><a href=https://github.com/containerd/containerd/releases>Releases · containerd/containerd</a></p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>wget https://github.com/opencontainers/runc/releases/download/v1.1.2/runc.amd64
cp runc.amd64 /usr/local/bin/runc   <span style=color:#080;font-style:italic>#把runc直接拷贝即可</span>
chmod +x  /usr/local/bin/runc
cp /usr/local/bin/runc /usr/bin
cp /usr/local/bin/runc /usr/local/sbin/

wget https://github.com/containerd/containerd/releases/download/v1.6.4/cri-containerd-cni-1.6.4-linux-amd64.tar.gz
tar xf cri-containerd-cni-1.6.4-linux-amd64.tar.gz -C /

root@worker02:~# containerd --version
containerd github.com/containerd/containerd v1.6.4 212e8b6fa2f44b9c21b2798135fc6fb7c53efc16

</code></pre></div><p>通过装好的node-cp查看containerd的服务</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@cp:~# systemctl status containerd
● containerd.service - containerd container runtime
     Loaded: loaded **<span style=color:#666>(</span>/lib/systemd/system/containerd.service**; enabled; vendor preset: enabled<span style=color:#666>)</span>
     Active: active <span style=color:#666>(</span>running<span style=color:#666>)</span> since Wed 2022-06-01 06:19:25 UTC; 3h 5min ago
       Docs: https://containerd.io
   Main PID: <span style=color:#666>36533</span> <span style=color:#666>(</span>containerd<span style=color:#666>)</span>

root@cp:~# cat /lib/systemd/system/containerd.service
<span style=color:#080;font-style:italic># Copyright The containerd Authors.</span>
<span style=color:#080;font-style:italic>#</span>
<span style=color:#080;font-style:italic># Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);</span>
<span style=color:#080;font-style:italic># you may not use this file except in compliance with the License.</span>
<span style=color:#080;font-style:italic># You may obtain a copy of the License at</span>
<span style=color:#080;font-style:italic>#</span>
<span style=color:#080;font-style:italic>#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span style=color:#080;font-style:italic>#</span>
<span style=color:#080;font-style:italic># Unless required by applicable law or agreed to in writing, software</span>
<span style=color:#080;font-style:italic># distributed under the License is distributed on an &#34;AS IS&#34; BASIS,</span>
<span style=color:#080;font-style:italic># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span style=color:#080;font-style:italic># See the License for the specific language governing permissions and</span>
<span style=color:#080;font-style:italic># limitations under the License.</span>

<span style=color:#666>[</span>Unit<span style=color:#666>]</span>
<span style=color:#b8860b>Description</span><span style=color:#666>=</span>containerd container runtime
<span style=color:#b8860b>Documentation</span><span style=color:#666>=</span>https://containerd.io
<span style=color:#b8860b>After</span><span style=color:#666>=</span>network.target local-fs.target

<span style=color:#666>[</span>Service<span style=color:#666>]</span>
<span style=color:#b8860b>ExecStartPre</span><span style=color:#666>=</span>-/sbin/modprobe overlay
<span style=color:#b8860b>ExecStart</span><span style=color:#666>=</span>/usr/bin/containerd

<span style=color:#b8860b>Type</span><span style=color:#666>=</span>notify
<span style=color:#b8860b>Delegate</span><span style=color:#666>=</span>yes
<span style=color:#b8860b>KillMode</span><span style=color:#666>=</span>process
<span style=color:#b8860b>Restart</span><span style=color:#666>=</span>always
<span style=color:#b8860b>RestartSec</span><span style=color:#666>=</span><span style=color:#666>5</span>
<span style=color:#080;font-style:italic># Having non-zero Limit*s causes performance problems due to accounting overhead</span>
<span style=color:#080;font-style:italic># in the kernel. We recommend using cgroups to do container-local accounting.</span>
<span style=color:#b8860b>LimitNPROC</span><span style=color:#666>=</span>infinity
<span style=color:#b8860b>LimitCORE</span><span style=color:#666>=</span>infinity
<span style=color:#b8860b>LimitNOFILE</span><span style=color:#666>=</span>infinity
<span style=color:#080;font-style:italic># Comment TasksMax if your systemd version does not supports it.</span>
<span style=color:#080;font-style:italic># Only systemd 226 and above support this version.</span>
<span style=color:#b8860b>TasksMax</span><span style=color:#666>=</span>infinity
<span style=color:#b8860b>OOMScoreAdjust</span><span style=color:#666>=</span>-999

<span style=color:#666>[</span>Install<span style=color:#666>]</span>
<span style=color:#b8860b>WantedBy</span><span style=color:#666>=</span>multi-user.target

</code></pre></div><p>而离线安装的在/etc/systemd/system/containerd.service，也是通过systemctl status containerd查看</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@worker02:~# cat /etc/systemd/system/containerd.service
<span style=color:#080;font-style:italic># Copyright The containerd Authors.</span>
<span style=color:#080;font-style:italic>#</span>
<span style=color:#080;font-style:italic># Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);</span>
<span style=color:#080;font-style:italic># you may not use this file except in compliance with the License.</span>
<span style=color:#080;font-style:italic># You may obtain a copy of the License at</span>
<span style=color:#080;font-style:italic>#</span>
<span style=color:#080;font-style:italic>#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span style=color:#080;font-style:italic>#</span>
<span style=color:#080;font-style:italic># Unless required by applicable law or agreed to in writing, software</span>
<span style=color:#080;font-style:italic># distributed under the License is distributed on an &#34;AS IS&#34; BASIS,</span>
<span style=color:#080;font-style:italic># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span style=color:#080;font-style:italic># See the License for the specific language governing permissions and</span>
<span style=color:#080;font-style:italic># limitations under the License.</span>

<span style=color:#666>[</span>Unit<span style=color:#666>]</span>
<span style=color:#b8860b>Description</span><span style=color:#666>=</span>containerd container runtime
<span style=color:#b8860b>Documentation</span><span style=color:#666>=</span>https://containerd.io
<span style=color:#b8860b>After</span><span style=color:#666>=</span>network.target local-fs.target

<span style=color:#666>[</span>Service<span style=color:#666>]</span>
<span style=color:#b8860b>ExecStartPre</span><span style=color:#666>=</span>-/sbin/modprobe overlay
<span style=color:#b8860b>ExecStart</span><span style=color:#666>=</span>/usr/local/bin/containerd

<span style=color:#b8860b>Type</span><span style=color:#666>=</span>notify
<span style=color:#b8860b>Delegate</span><span style=color:#666>=</span>yes
<span style=color:#b8860b>KillMode</span><span style=color:#666>=</span>process
<span style=color:#b8860b>Restart</span><span style=color:#666>=</span>always
<span style=color:#b8860b>RestartSec</span><span style=color:#666>=</span><span style=color:#666>5</span>
<span style=color:#080;font-style:italic># Having non-zero Limit*s causes performance problems due to accounting overhead</span>
<span style=color:#080;font-style:italic># in the kernel. We recommend using cgroups to do container-local accounting.</span>
<span style=color:#b8860b>LimitNPROC</span><span style=color:#666>=</span>infinity
<span style=color:#b8860b>LimitCORE</span><span style=color:#666>=</span>infinity
<span style=color:#b8860b>LimitNOFILE</span><span style=color:#666>=</span>infinity
<span style=color:#080;font-style:italic># Comment TasksMax if your systemd version does not supports it.</span>
<span style=color:#080;font-style:italic># Only systemd 226 and above support this version.</span>
<span style=color:#b8860b>TasksMax</span><span style=color:#666>=</span>infinity
<span style=color:#b8860b>OOMScoreAdjust</span><span style=color:#666>=</span>-999

<span style=color:#666>[</span>Install<span style=color:#666>]</span>
<span style=color:#b8860b>WantedBy</span><span style=color:#666>=</span>multi-user.target

</code></pre></div><p>启动服务</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@worker02:~# systemctl daemon-reload
root@worker02:~# systemctl restart containerd
</code></pre></div><p>创建配置目录</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>mkdir -p /etc/containerd
</code></pre></div><p>从装好的node传递配置文件/etc/containerd/config.toml和/etc/crictl.yaml，也可以按照前面的方法生成后修改</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@cp:~# scp /etc/containerd/config.toml root@worker02:/etc/containerd/config.toml

root@cp:~# scp /etc/crictl.yaml root@worker02:/etc/crictl.yaml

systemctl restart containerd
</code></pre></div><h2 id=kubeadm初始化集群>Kubeadm初始化集群</h2>
<p>查看需要多少images（报错是不能访问k8s.gcr.io）</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@cp:~# kubeadm config images list
W0601 06:40:29.809756   <span style=color:#666>39745</span> version.go:103<span style=color:#666>]</span> could not fetch a Kubernetes version from the internet: unable to get URL <span style=color:#b44>&#34;https://dl.k8s.io/release/stable-1.txt&#34;</span>: Get <span style=color:#b44>&#34;https://storage.googleapis.com/kubernetes-release/release/stable-1.txt&#34;</span>: context deadline exceeded <span style=color:#666>(</span>Client.Timeout exceeded <span style=color:#a2f;font-weight:700>while</span> awaiting headers<span style=color:#666>)</span>
W0601 06:40:29.809867   <span style=color:#666>39745</span> version.go:104<span style=color:#666>]</span> falling back to the <span style=color:#a2f>local</span> client version: v1.24.1
k8s.gcr.io/kube-apiserver:v1.24.1
k8s.gcr.io/kube-controller-manager:v1.24.1
k8s.gcr.io/kube-scheduler:v1.24.1
k8s.gcr.io/kube-proxy:v1.24.1
k8s.gcr.io/pause:3.7
k8s.gcr.io/etcd:3.5.3-0
k8s.gcr.io/coredns/coredns:v1.8.6
</code></pre></div><p>使用kubeadm命令初始化集群</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>kubeadm init --kubernetes-version<span style=color:#666>=</span>1.24.1  --apiserver-advertise-address<span style=color:#666>=</span>192.168.81.21 --apiserver-bind-port<span style=color:#666>=</span><span style=color:#666>6443</span> --image-repository<span style=color:#666>=</span>registry.cn-hangzhou.aliyuncs.com/google_containers --pod-network-cidr<span style=color:#666>=</span>10.211.0.0/16 --service-cidr<span style=color:#666>=</span>10.96.0.0/12 --cri-socket<span style=color:#666>=</span>unix:///run/containerd/containerd.sock --ignore-preflight-errors<span style=color:#666>=</span>Swap
</code></pre></div><p>可以用kubeadm init —help来查看语法。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@cp:~# kubeadm init --kubernetes-version<span style=color:#666>=</span>1.24.1  --apiserver-advertise-address<span style=color:#666>=</span>192.168.81.21 --apiserver-bind-port<span style=color:#666>=</span><span style=color:#666>6443</span> --image-repository<span style=color:#666>=</span>registry.cn-hangzhou.aliyuncs.com/google_containers --pod-network-cidr<span style=color:#666>=</span>10.211.0.0/16 --service-cidr<span style=color:#666>=</span>10.96.0.0/12 --cri-socket<span style=color:#666>=</span>unix:///run/containerd/containerd.sock --ignore-preflight-errors<span style=color:#666>=</span>Swap
<span style=color:#666>[</span>init<span style=color:#666>]</span> Using Kubernetes version: v1.24.1
<span style=color:#666>[</span>preflight<span style=color:#666>]</span> Running pre-flight checks
<span style=color:#666>[</span>preflight<span style=color:#666>]</span> Pulling images required <span style=color:#a2f;font-weight:700>for</span> setting up a Kubernetes cluster
......

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p <span style=color:#b8860b>$HOME</span>/.kube
  sudo cp -i /etc/kubernetes/admin.conf <span style=color:#b8860b>$HOME</span>/.kube/config
  sudo chown <span style=color:#a2f;font-weight:700>$(</span>id -u<span style=color:#a2f;font-weight:700>)</span>:<span style=color:#a2f;font-weight:700>$(</span>id -g<span style=color:#a2f;font-weight:700>)</span> <span style=color:#b8860b>$HOME</span>/.kube/config

Alternatively, <span style=color:#a2f;font-weight:700>if</span> you are the root user, you can run:

  <span style=color:#a2f>export</span> <span style=color:#b8860b>KUBECONFIG</span><span style=color:#666>=</span>/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run <span style=color:#b44>&#34;kubectl apply -f [podnetwork].yaml&#34;</span> with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 192.168.81.21:6443 --token fybv6g.xlt3snl52qs5wyoo <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>        --discovery-token-ca-cert-hash sha256:8545518e775368c0982638b9661355e6682a1f3ba98386b4ca0453449edc97ca
</code></pre></div><p>已经下好的images</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@cp:~# crictl images ls
IMAGE                                                                         TAG                 IMAGE ID            SIZE
registry.cn-hangzhou.aliyuncs.com/google_containers/coredns                   v1.8.6              a4ca41631cc7a       13.6MB
registry.cn-hangzhou.aliyuncs.com/google_containers/etcd                      3.5.3-0             aebe758cef4cd       102MB
registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver            v1.24.1             e9f4b425f9192       33.8MB
registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager   v1.24.1             b4ea7e648530d       31MB
registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy                v1.24.1             beb86f5d8e6cd       39.5MB
registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler            v1.24.1             18688a72645c5       15.5MB
registry.cn-hangzhou.aliyuncs.com/google_containers/pause                     3.6                 6270bb605e12e       302kB
registry.cn-hangzhou.aliyuncs.com/google_containers/pause                     3.7                 221177c6082a8       311kB

<span style=color:#080;font-style:italic>#如果用ctr命令需要指定namespace</span>

root@cp:~# ctr namespace ls
NAME    LABELS
default        
k8s.io         

root@cp:~# ctr -n k8s.io image ls
REF                                                                                                                                                 TYPE                                                      DIGEST                                                                  SIZE      PLATFORMS                                                                    LABELS                          
registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.6                                                                                  application/vnd.docker.distribution.manifest.list.v2+json sha256:5b6ec0d6de9baaf3e92d0f66cd96a25b9edbce8716f5f15dcd1a616b3abd590e 13.0 MiB  linux/amd64,linux/arm,linux/arm64,linux/mips64le,linux/ppc64le,linux/s390x   io.cri-containerd.image<span style=color:#666>=</span>managed
registry.cn-hangzhou.aliyuncs.com/google_containers/coredns@sha256:5b6ec0d6de9baaf3e92d0f66cd96a25b9edbce8716f5f15dcd1a616b3abd590e                 application/vnd.docker.distribution.manifest.list.v2+json sha256:5b6ec0d6de9baaf3e92d0f66cd96a25b9edbce8716f5f15dcd1a616b3abd590e 13.0 MiB  linux/amd64,linux/arm,linux/arm64,linux/mips64le,linux/ppc64le,linux/s390x   io.cri-containerd.image<span style=color:#666>=</span>managed
registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.5.3-0                                                                                    application/vnd.docker.distribution.manifest.list.v2+json sha256:13f53ed1d91e2e11aac476ee9a0269fdda6cc4874eba903efd40daf50c55eee5 97.4 MiB  linux/amd64,linux/arm/v7,linux/arm64,linux/ppc64le,linux/s390x,windows/amd64 io.cri-containerd.image<span style=color:#666>=</span>managed
registry.cn-hangzhou.aliyuncs.com/google_containers/etcd@sha256:13f53ed1d91e2e11aac476ee9a0269fdda6cc4874eba903efd40daf50c55eee5                    application/vnd.docker.distribution.manifest.list.v2+json sha256:13f53ed1d91e2e11aac476ee9a0269fdda6cc4874eba903efd40daf50c55eee5 97.4 MiB  linux/amd64,linux/arm/v7,linux/arm64,linux/ppc64le,linux/s390x,windows/amd64 io.cri-containerd.image<span style=color:#666>=</span>managed
registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.24.1                                                                          application/vnd.docker.distribution.manifest.list.v2+json sha256:ad9608e8a9d758f966b6ca6795b50a4723982328194bde214804b21efd48da44 32.2 MiB  linux/amd64,linux/arm/v7,linux/arm64,linux/ppc64le,linux/s390x               io.cri-containerd.image<span style=color:#666>=</span>managed
registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver@sha256:ad9608e8a9d758f966b6ca6795b50a4723982328194bde214804b21efd48da44          application/vnd.docker.distribution.manifest.list.v2+json sha256:ad9608e8a9d758f966b6ca6795b50a4723982328194bde214804b21efd48da44 32.2 MiB  linux/amd64,linux/arm/v7,linux/arm64,linux/ppc64le,linux/s390x               io.cri-containerd.image<span style=color:#666>=</span>managed
registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.24.1                                                                 application/vnd.docker.distribution.manifest.list.v2+json sha256:594a3f5bbdd0419ac57d580da8dfb061237fa48d0c9909991a3af70630291f7a 29.6 MiB  linux/amd64,linux/arm/v7,linux/arm64,linux/ppc64le,linux/s390x               io.cri-containerd.image<span style=color:#666>=</span>managed
registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager@sha256:594a3f5bbdd0419ac57d580da8dfb061237fa48d0c9909991a3af70630291f7a application/vnd.docker.distribution.manifest.list.v2+json sha256:594a3f5bbdd0419ac57d580da8dfb061237fa48d0c9909991a3af70630291f7a 29.6 MiB  linux/amd64,linux/arm/v7,linux/arm64,linux/ppc64le,linux/s390x               io.cri-containerd.image<span style=color:#666>=</span>managed
registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.24.1                                                                              application/vnd.docker.distribution.manifest.list.v2+json sha256:1652df3138207570f52ae0be05cbf26c02648e6a4c30ced3f779fe3d6295ad6d 37.7 MiB  linux/amd64,linux/arm/v7,linux/arm64,linux/ppc64le,linux/s390x               io.cri-containerd.image<span style=color:#666>=</span>managed
registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy@sha256:1652df3138207570f52ae0be05cbf26c02648e6a4c30ced3f779fe3d6295ad6d              application/vnd.docker.distribution.manifest.list.v2+json sha256:1652df3138207570f52ae0be05cbf26c02648e6a4c30ced3f779fe3d6295ad6d 37.7 MiB  linux/amd64,linux/arm/v7,linux/arm64,linux/ppc64le,linux/s390x               io.cri-containerd.image<span style=color:#666>=</span>managed
registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.24.1                                                                          application/vnd.docker.distribution.manifest.list.v2+json sha256:0d2de567157e3fb97dfa831620a3dc38d24b05bd3721763a99f3f73b8cbe99c9 14.8 MiB  linux/amd64,linux/arm/v7,linux/arm64,linux/ppc64le,linux/s390x               io.cri-containerd.image<span style=color:#666>=</span>managed
registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler@sha256:0d2de567157e3fb97dfa831620a3dc38d24b05bd3721763a99f3f73b8cbe99c9          application/vnd.docker.distribution.manifest.list.v2+json sha256:0d2de567157e3fb97dfa831620a3dc38d24b05bd3721763a99f3f73b8cbe99c9 14.8 MiB  linux/amd64,linux/arm/v7,linux/arm64,linux/ppc64le,linux/s390x               io.cri-containerd.image<span style=color:#666>=</span>managed
registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6                                                                                       application/vnd.docker.distribution.manifest.list.v2+json sha256:3d380ca8864549e74af4b29c10f9cb0956236dfb01c40ca076fb6c37253234db 294.7 KiB linux/amd64,linux/arm/v7,linux/arm64,linux/ppc64le,linux/s390x,windows/amd64 io.cri-containerd.image<span style=color:#666>=</span>managed
registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.7                                                                                       application/vnd.docker.distribution.manifest.list.v2+json sha256:bb6ed397957e9ca7c65ada0db5c5d1c707c9c8afc80a94acbe69f3ae76988f0c 304.0 KiB linux/amd64,linux/arm/v7,linux/arm64,linux/ppc64le,linux/s390x,windows/amd64 io.cri-containerd.image<span style=color:#666>=</span>managed
registry.cn-hangzhou.aliyuncs.com/google_containers/pause@sha256:3d380ca8864549e74af4b29c10f9cb0956236dfb01c40ca076fb6c37253234db                   application/vnd.docker.distribution.manifest.list.v2+json sha256:3d380ca8864549e74af4b29c10f9cb0956236dfb01c40ca076fb6c37253234db 294.7 KiB linux/amd64,linux/arm/v7,linux/arm64,linux/ppc64le,linux/s390x,windows/amd64 io.cri-containerd.image<span style=color:#666>=</span>managed
registry.cn-hangzhou.aliyuncs.com/google_containers/pause@sha256:bb6ed397957e9ca7c65ada0db5c5d1c707c9c8afc80a94acbe69f3ae76988f0c                   application/vnd.docker.distribution.manifest.list.v2+json sha256:bb6ed397957e9ca7c65ada0db5c5d1c707c9c8afc80a94acbe69f3ae76988f0c 304.0 KiB linux/amd64,linux/arm/v7,linux/arm64,linux/ppc64le,linux/s390x,windows/amd64 io.cri-containerd.image<span style=color:#666>=</span>managed
sha256:18688a72645c5d34e1cc70d8deb5bef4fc6c9073bb1b53c7812856afc1de1237                                                                             application/vnd.docker.distribution.manifest.list.v2+json sha256:0d2de567157e3fb97dfa831620a3dc38d24b05bd3721763a99f3f73b8cbe99c9 14.8 MiB  linux/amd64,linux/arm/v7,linux/arm64,linux/ppc64le,linux/s390x               io.cri-containerd.image<span style=color:#666>=</span>managed
sha256:221177c6082a88ea4f6240ab2450d540955ac6f4d5454f0e15751b653ebda165                                                                             application/vnd.docker.distribution.manifest.list.v2+json sha256:bb6ed397957e9ca7c65ada0db5c5d1c707c9c8afc80a94acbe69f3ae76988f0c 304.0 KiB linux/amd64,linux/arm/v7,linux/arm64,linux/ppc64le,linux/s390x,windows/amd64 io.cri-containerd.image<span style=color:#666>=</span>managed
sha256:6270bb605e12e581514ada5fd5b3216f727db55dc87d5889c790e4c760683fee                                                                             application/vnd.docker.distribution.manifest.list.v2+json sha256:3d380ca8864549e74af4b29c10f9cb0956236dfb01c40ca076fb6c37253234db 294.7 KiB linux/amd64,linux/arm/v7,linux/arm64,linux/ppc64le,linux/s390x,windows/amd64 io.cri-containerd.image<span style=color:#666>=</span>managed
sha256:a4ca41631cc7ac19ce1be3ebf0314ac5f47af7c711f17066006db82ee3b75b03                                                                             application/vnd.docker.distribution.manifest.list.v2+json sha256:5b6ec0d6de9baaf3e92d0f66cd96a25b9edbce8716f5f15dcd1a616b3abd590e 13.0 MiB  linux/amd64,linux/arm,linux/arm64,linux/mips64le,linux/ppc64le,linux/s390x   io.cri-containerd.image<span style=color:#666>=</span>managed
sha256:aebe758cef4cd05b9f8cee39758227714d02f42ef3088023c1e3cd454f927a2b                                                                             application/vnd.docker.distribution.manifest.list.v2+json sha256:13f53ed1d91e2e11aac476ee9a0269fdda6cc4874eba903efd40daf50c55eee5 97.4 MiB  linux/amd64,linux/arm/v7,linux/arm64,linux/ppc64le,linux/s390x,windows/amd64 io.cri-containerd.image<span style=color:#666>=</span>managed
sha256:b4ea7e648530d171b38f67305e22caf49f9d968d71c558e663709b805076538d                                                                             application/vnd.docker.distribution.manifest.list.v2+json sha256:594a3f5bbdd0419ac57d580da8dfb061237fa48d0c9909991a3af70630291f7a 29.6 MiB  linux/amd64,linux/arm/v7,linux/arm64,linux/ppc64le,linux/s390x               io.cri-containerd.image<span style=color:#666>=</span>managed
sha256:beb86f5d8e6cd2234ca24649b74bd10e1e12446764560a3804d85dd6815d0a18                                                                             application/vnd.docker.distribution.manifest.list.v2+json sha256:1652df3138207570f52ae0be05cbf26c02648e6a4c30ced3f779fe3d6295ad6d 37.7 MiB  linux/amd64,linux/arm/v7,linux/arm64,linux/ppc64le,linux/s390x               io.cri-containerd.image<span style=color:#666>=</span>managed
sha256:e9f4b425f9192c11c0fa338cabe04f832aa5cea6dcbba2d1bd2a931224421693                                                                             application/vnd.docker.distribution.manifest.list.v2+json sha256:ad9608e8a9d758f966b6ca6795b50a4723982328194bde214804b21efd48da44 32.2 MiB  linux/amd64,linux/arm/v7,linux/arm64,linux/ppc64le,linux/s390x               io.cri-containerd.image<span style=color:#666>=</span>managed
</code></pre></div><p>使用calico作为CNI</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@cp:~# kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
configmap/calico-config created
customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/caliconodestatuses.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ipreservations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/kubecontrollersconfigurations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org created
clusterrole.rbac.authorization.k8s.io/calico-kube-controllers created
clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created
clusterrole.rbac.authorization.k8s.io/calico-node created
clusterrolebinding.rbac.authorization.k8s.io/calico-node created
daemonset.apps/calico-node created
serviceaccount/calico-node created
deployment.apps/calico-kube-controllers created
serviceaccount/calico-kube-controllers created
poddisruptionbudget.policy/calico-kube-controllers created
</code></pre></div><p>Worker节点加入</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@worker01:~# kubeadm join 192.168.81.21:6443 --token fybv6g.xlt3snl52qs5wyoo <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>&gt;         --discovery-token-ca-cert-hash sha256:8545518e775368c0982638b9661355e6682a1f3ba98386b4ca0453449edc97ca
<span style=color:#666>[</span>preflight<span style=color:#666>]</span> Running pre-flight checks
<span style=color:#666>[</span>preflight<span style=color:#666>]</span> Reading configuration from the cluster...
<span style=color:#666>[</span>preflight<span style=color:#666>]</span> FYI: You can look at this config file with <span style=color:#b44>&#39;kubectl -n kube-system get cm kubeadm-config -o yaml&#39;</span>
<span style=color:#666>[</span>kubelet-start<span style=color:#666>]</span> Writing kubelet configuration to file <span style=color:#b44>&#34;/var/lib/kubelet/config.yaml&#34;</span>
<span style=color:#666>[</span>kubelet-start<span style=color:#666>]</span> Writing kubelet environment file with flags to file <span style=color:#b44>&#34;/var/lib/kubelet/kubeadm-flags.env&#34;</span>
<span style=color:#666>[</span>kubelet-start<span style=color:#666>]</span> Starting the kubelet
<span style=color:#666>[</span>kubelet-start<span style=color:#666>]</span> Waiting <span style=color:#a2f;font-weight:700>for</span> the kubelet to perform the TLS Bootstrap...

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run <span style=color:#b44>&#39;kubectl get nodes&#39;</span> on the control-plane to see this node join the cluster.

<span style=color:#080;font-style:italic>#CP check:</span>
root@cp:/home/zyi# kubectl get node -owide
NAME       STATUS   ROLES           AGE   VERSION   INTERNAL-IP     EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME
cp         Ready    control-plane   30h   v1.24.1   192.168.81.21   &lt;none&gt;        Ubuntu 20.04.4 LTS   5.4.0-113-generic   containerd://1.6.4
worker01   Ready    &lt;none&gt;          30h   v1.24.1   192.168.81.22   &lt;none&gt;        Ubuntu 20.04.4 LTS   5.4.0-113-generic   containerd://1.6.4
worker02   Ready    &lt;none&gt;          27h   v1.24.1   192.168.81.23   &lt;none&gt;        Ubuntu 20.04.4 LTS   5.4.0-113-generic   containerd://1.6.4
root@cp:~# kubectl get po -A -owide
NAMESPACE     NAME                                       READY   STATUS    RESTARTS   AGE     IP              NODE       NOMINATED NODE   READINESS GATES
kube-system   calico-kube-controllers-56cdb7c587-v46wk   1/1     Running   <span style=color:#666>0</span>          118m    10.211.5.3      worker01   &lt;none&gt;           &lt;none&gt;
kube-system   calico-node-2qq4n                          1/1     Running   <span style=color:#666>0</span>          118m    192.168.81.21   cp         &lt;none&gt;           &lt;none&gt;
kube-system   calico-node-slnp9                          1/1     Running   <span style=color:#666>0</span>          2m27s   192.168.81.23   worker02   &lt;none&gt;           &lt;none&gt;
kube-system   calico-node-v2xd8                          1/1     Running   <span style=color:#666>0</span>          118m    192.168.81.22   worker01   &lt;none&gt;           &lt;none&gt;
kube-system   coredns-7f74c56694-4b4wp                   1/1     Running   <span style=color:#666>0</span>          3h      10.211.5.1      worker01   &lt;none&gt;           &lt;none&gt;
kube-system   coredns-7f74c56694-mmvgb                   1/1     Running   <span style=color:#666>0</span>          3h      10.211.5.2      worker01   &lt;none&gt;           &lt;none&gt;
kube-system   etcd-cp                                    1/1     Running   <span style=color:#666>0</span>          3h      192.168.81.21   cp         &lt;none&gt;           &lt;none&gt;
kube-system   kube-apiserver-cp                          1/1     Running   <span style=color:#666>0</span>          3h      192.168.81.21   cp         &lt;none&gt;           &lt;none&gt;
kube-system   kube-controller-manager-cp                 1/1     Running   <span style=color:#666>0</span>          3h      192.168.81.21   cp         &lt;none&gt;           &lt;none&gt;
kube-system   kube-proxy-4n2jk                           1/1     Running   <span style=color:#666>0</span>          2m27s   192.168.81.23   worker02   &lt;none&gt;           &lt;none&gt;
kube-system   kube-proxy-8zdvt                           1/1     Running   <span style=color:#666>0</span>          169m    192.168.81.22   worker01   &lt;none&gt;           &lt;none&gt;
kube-system   kube-proxy-rpf78                           1/1     Running   <span style=color:#666>0</span>          3h      192.168.81.21   cp         &lt;none&gt;           &lt;none&gt;
kube-system   kube-scheduler-cp                          1/1     Running   <span style=color:#666>0</span>          3h      192.168.81.21   cp         &lt;none&gt;           &lt;none&gt;
</code></pre></div><h1 id=使用docker运行时创建集群>使用Docker运行时创建集群</h1>
<p>安装官网的描述可以使用<strong>Docker Engine创建集群</strong></p>
<blockquote>
<p><strong>Note: 以下操作假设你使用 <code>[cri-dockerd](https://github.com/Mirantis/cri-dockerd)</code> 适配器来将 Docker Engine 与 Kubernetes 集成。</strong></p>
</blockquote>
<ol>
<li>
<p>在你的每个节点上，遵循<a href=https://docs.docker.com/engine/install/#server>安装 Docker 引擎</a>指南为你的 Linux 发行版安装 Docker</p>
</li>
<li>
<p>按照源代码仓库中的说明安装 <code>[cri-dockerd](https://github.com/Mirantis/cri-dockerd)</code>。</p>
<p>对于 <code>cri-dockerd</code>，默认情况下，CRI 套接字是 <code>/run/cri-dockerd.sock</code></p>
</li>
<li>
<p>初始化kubernetes Cluster</p>
</li>
</ol>
<h2 id=安装docker-ce>安装Docker-ce</h2>
<p>在线安装方式，配置软件源等</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
add-apt-repository <span style=color:#b44>&#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu </span><span style=color:#a2f;font-weight:700>$(</span>lsb_release -cs<span style=color:#a2f;font-weight:700>)</span><span style=color:#b44> stable&#34;</span>
apt update
apt install -y containerd.io docker-ce docker-ce-cli

注意：
默认情况下，docker服务使用的就是containerd接口服务，
通过 journalctl －u docker.service
可知：unix:///run/containerd/containerd.sock

</code></pre></div><p>查看Docker info</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@worker01:~# docker info
Client:
 ...

Server:
 Containers: <span style=color:#666>0</span>
  ...
 Server Version: 20.10.16
 Storage Driver: overlay2
  Backing Filesystem: extfs
  Supports d_type: <span style=color:#a2f>true</span>
  Native Overlay Diff: <span style=color:#a2f>true</span>
  userxattr: <span style=color:#a2f>false</span>
 Logging Driver: json-file
 **Cgroup Driver: cgroupfs**
 Cgroup Version: <span style=color:#666>1</span>
...
WARNING: No swap limit support
</code></pre></div><p>上面可以看到docker的default Cgroup Driver是cgroupfs，而查看kubelet却是systemd</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@worker01:~# journalctl -u kubelet | grep systemd |more
Jun <span style=color:#666>03</span> 02:48:41 worker01 systemd<span style=color:#666>[</span>1<span style=color:#666>]</span>: kubelet.service: Main process exited
, <span style=color:#b8860b>code</span><span style=color:#666>=</span>exited, <span style=color:#b8860b>status</span><span style=color:#666>=</span>1/FAILURE
Jun <span style=color:#666>03</span> 02:48:41 worker01 systemd<span style=color:#666>[</span>1<span style=color:#666>]</span>: kubelet.service: Failed with result
<span style=color:#b44>&#39;exit-code&#39;</span>.
Jun <span style=color:#666>03</span> 02:48:52 worker01 systemd<span style=color:#666>[</span>1<span style=color:#666>]</span>: kubelet.service: Scheduled restart j
ob, restart counter is at 4441.
Jun <span style=color:#666>03</span> 02:48:52 worker01 systemd<span style=color:#666>[</span>1<span style=color:#666>]</span>: Stopped kubelet: The Kubernetes Node
 Agent.
Jun <span style=color:#666>03</span> 02:48:52 worker01 systemd<span style=color:#666>[</span>1<span style=color:#666>]</span>: Started kubelet: The Kubernetes Node
 Agent.
Jun <span style=color:#666>03</span> 02:48:52 worker01 kubelet<span style=color:#666>[</span>97187<span style=color:#666>]</span>:       --cgroup-driver string    
                                 Driver that the kubelet uses to manipula
te cgroups on the host.  Possible values: <span style=color:#b44>&#39;cgroupfs&#39;</span>, <span style=color:#b44>&#39;systemd&#39;</span> <span style=color:#666>(</span>default
<span style=color:#b44>&#34;cgroupfs&#34;</span><span style=color:#666>)</span> <span style=color:#666>(</span>DEPRECATED: This parameter should be <span style=color:#a2f>set</span> via the config file
 specified by the Kubelet<span>&#39;</span>s --config flag. See https://kubernetes.io/docs
/tasks/administer-cluster/kubelet-config-file/ <span style=color:#a2f;font-weight:700>for</span> more information.<span style=color:#666>)</span>
Jun <span style=color:#666>03</span> 02:48:52 worker01 systemd<span style=color:#666>[</span>1<span style=color:#666>]</span>: kubelet.service: Main process exited
, <span style=color:#b8860b>code</span><span style=color:#666>=</span>exited, <span style=color:#b8860b>status</span><span style=color:#666>=</span>1/FAILURE
</code></pre></div><p>下面来改docker的Cgroup Dirver的参数（每台都做）：</p>
<p>创建专属的systemd服务管理目录</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>mkdir -p /etc/systemd/system/docker.service.d
</code></pre></div><p>定制配置文件</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>tee /etc/docker/daemon.json <span style=color:#b44>&lt;&lt;EOF
</span><span style=color:#b44>{
</span><span style=color:#b44>  &#34;exec-opts&#34;: [&#34;native.cgroupdriver=systemd&#34;],
</span><span style=color:#b44>  &#34;log-driver&#34;: &#34;json-file&#34;,
</span><span style=color:#b44>  &#34;log-opts&#34;: {
</span><span style=color:#b44>    &#34;max-size&#34;: &#34;100m&#34;
</span><span style=color:#b44>},
</span><span style=color:#b44>  &#34;storage-driver&#34;: &#34;overlay2&#34;
</span><span style=color:#b44>}
</span><span style=color:#b44>EOF</span>

<span style=color:#080;font-style:italic># 重新启动服务</span>
systemctl daemon-reload
systemctl restart docker
systemctl <span style=color:#a2f>enable</span> docker

root@worker01:~# docker info |grep Cgroup
 Cgroup Driver: systemd
 Cgroup Version: <span style=color:#666>1</span>
WARNING: No swap limit support
</code></pre></div><h2 id=获取cri-dockers插件以支持docker>获取cri-dockers插件以支持docker</h2>
<p>插件cri-dockerd安装方式</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>mkdir -p /data/softs <span style=color:#666>&amp;&amp;</span> <span style=color:#a2f>cd</span> /data/softs

wget https://github.com/Mirantis/cri-dockerd/releases/download/v0.2.1/cri-dockerd-0.2.1.amd64.tgz
tar xf cri-dockerd-0.2.1.amd64.tgz
mv cri-dockerd/cri-dockerd /usr/local/bin/

<span style=color:#080;font-style:italic>#检查效果</span>
cri-dockerd --version

root@master:/data/softs# cri-dockerd --version
cri-dockerd 0.2.1 <span style=color:#666>(</span>HEAD<span style=color:#666>)</span>
</code></pre></div><p>定制服务文件/etc/systemd/system/cri-docker.service，为cri-dockerd启动读取</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#666>[</span>Unit<span style=color:#666>]</span>
<span style=color:#b8860b>Description</span><span style=color:#666>=</span>CRI Interface <span style=color:#a2f;font-weight:700>for</span> Docker Application container Engine
<span style=color:#b8860b>Documentation</span><span style=color:#666>=</span>https://docs.mirantis.com
<span style=color:#b8860b>After</span><span style=color:#666>=</span>network-online.target firewalld.service docker.service
<span style=color:#b8860b>Wants</span><span style=color:#666>=</span>network-online.target

<span style=color:#666>[</span>Service<span style=color:#666>]</span>
<span style=color:#b8860b>Type</span><span style=color:#666>=</span>notify
<span style=color:#b8860b>ExecStart</span><span style=color:#666>=</span>/usr/local/bin/cri-dockerd --network-plugin<span style=color:#666>=</span>cni --cni-conf-dir<span style=color:#666>=</span>/etc/cni/net.d --cni-bin-dir<span style=color:#666>=</span>/opt/cni/bin --container-runtime-endpoint<span style=color:#666>=</span>unix:///var/run/cri-dockerd.sock --image-pull-progress-deadline<span style=color:#666>=</span>30s --pod-infra-container-image<span style=color:#666>=</span>registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6 --cri-dockerd-root-directory<span style=color:#666>=</span>/var/lib/dockershim --docker-endpoint<span style=color:#666>=</span>unix:///var/run/docker.sock --cri-dockerd-root-directory<span style=color:#666>=</span>/var/lib/docker
<span style=color:#b8860b>ExecReload</span><span style=color:#666>=</span>/bin/kill -s HUP <span style=color:#b8860b>$MAINPID</span>

<span style=color:#b8860b>TimeoutSec</span><span style=color:#666>=</span><span style=color:#666>0</span>
<span style=color:#b8860b>RestartSec</span><span style=color:#666>=</span><span style=color:#666>2</span>
<span style=color:#b8860b>Restart</span><span style=color:#666>=</span>always
<span style=color:#b8860b>StartLimitBurst</span><span style=color:#666>=</span><span style=color:#666>3</span>
<span style=color:#b8860b>StartLimitInterval</span><span style=color:#666>=</span>60s
<span style=color:#b8860b>LimitNOFILE</span><span style=color:#666>=</span>infinity
<span style=color:#b8860b>LimitNPROC</span><span style=color:#666>=</span>infinity
<span style=color:#b8860b>LimitCORE</span><span style=color:#666>=</span>infinity
<span style=color:#b8860b>TasksMax</span><span style=color:#666>=</span>infinity
<span style=color:#b8860b>Delegate</span><span style=color:#666>=</span>yes
<span style=color:#b8860b>killMode</span><span style=color:#666>=</span>process

<span style=color:#666>[</span>Install<span style=color:#666>]</span>
<span style=color:#b8860b>WantedBy</span><span style=color:#666>=</span>multi-user.target

</code></pre></div><p>定制专属的服务(Optional)socket文件/usr/lib/systemd/system/cri-docker.socket</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#666>[</span>Unit<span style=color:#666>]</span>
<span style=color:#b8860b>Description</span><span style=color:#666>=</span>CRI Docker Socket <span style=color:#a2f;font-weight:700>for</span> the API
<span style=color:#b8860b>PartOf</span><span style=color:#666>=</span>cri-docker.service

<span style=color:#666>[</span>Socket<span style=color:#666>]</span>
<span style=color:#b8860b>ListenStream</span><span style=color:#666>=</span>/var/run/cri-dockerd.sock
<span style=color:#b8860b>SocketMode</span><span style=color:#666>=</span><span style=color:#666>0660</span>
<span style=color:#b8860b>SocketUser</span><span style=color:#666>=</span>root
<span style=color:#b8860b>SocketGroup</span><span style=color:#666>=</span>docker

<span style=color:#666>[</span>Install<span style=color:#666>]</span>
<span style=color:#b8860b>WantedBy</span><span style=color:#666>=</span>sockets.target
</code></pre></div><p>启动服务</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>systemctl daemon-reload
systemctl <span style=color:#a2f>enable</span> cri-docker.service
systemctl restart cri-docker.service

systemctl status --no-pager cri-docker.service

<span style=color:#080;font-style:italic>#检测效果</span>
crictl --runtime-endpoint /var/run/cri-dockerd.sock ps

root@master:/data/softs# crictl --runtime-endpoint /var/run/cri-dockerd.sock ps
I0604 10:50:12.902161  <span style=color:#666>380647</span> util_unix.go:104<span style=color:#666>]</span> <span style=color:#b44>&#34;Using this format as endpoint is deprecated, please consider using full url format.&#34;</span> <span style=color:#b8860b>deprecatedFormat</span><span style=color:#666>=</span><span style=color:#b44>&#34;/var/run/cri-dockerd.sock&#34;</span> <span style=color:#b8860b>fullURLFormat</span><span style=color:#666>=</span><span style=color:#b44>&#34;unix:///var/run/cri-dockerd.sock&#34;</span>
I0604 10:50:12.911201  <span style=color:#666>380647</span> util_unix.go:104<span style=color:#666>]</span> <span style=color:#b44>&#34;Using this format as endpoint is deprecated, please consider using full url format.&#34;</span> <span style=color:#b8860b>deprecatedFormat</span><span style=color:#666>=</span><span style=color:#b44>&#34;/var/run/cri-dockerd.sock&#34;</span> <span style=color:#b8860b>fullURLFormat</span><span style=color:#666>=</span><span style=color:#b44>&#34;unix:///var/run/cri-dockerd.sock&#34;</span>
CONTAINER           IMAGE               CREATED             STATE               NAME                ATTEMPT             POD ID              POD
</code></pre></div><p>此时有go:104提示，以下yaml文件可以去掉前面的提示</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#080;font-style:italic># cat /etc/crictl.yaml</span>
runtime-endpoint: <span style=color:#b44>&#34;unix:///var/run/cri-dockerd.sock&#34;</span>
image-endpoint: <span style=color:#b44>&#34;unix:///var/run/cri-dockerd.sock&#34;</span>
timeout: <span style=color:#666>10</span>
debug: <span style=color:#a2f>false</span>
pull-image-on-create: <span style=color:#a2f>true</span>
disable-pull-on-run: <span style=color:#a2f>false</span>

</code></pre></div><p>测试效果</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>crictl ps

root@master:/data/softs# crictl ps
CONTAINER           IMAGE               CREATED             STATE               NAME                ATTEMPT             POD ID              POD
</code></pre></div><p>接下来，保证所有主机得到配置文件</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@master:/data/softs# scp /etc/systemd/system/cri-docker.service worker01:/etc/systemd/system/cri-docker.service
cri-docker.service                                                               100%  <span style=color:#666>934</span>     1.9MB/s   00:00    
root@master:/data/softs# scp /usr/lib/systemd/system/cri-docker.socket worker01:/usr/lib/systemd/system/cri-docker.socket
cri-docker.socket                                                                100%  <span style=color:#666>210</span>   458.5KB/s   00:00    
root@master:/data/softs# scp /etc/crictl.yaml worker01:/etc/crictl.yaml
crictl.yaml                                                                      100%  <span style=color:#666>183</span>   718.5KB/s   00:00
</code></pre></div><h2 id=创建集群>创建集群</h2>
<h3 id=kubelet改造所有node>kubelet改造，所有node</h3>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#080;font-style:italic>#cat/etc/systemd/system/kubelet.service.d/10-kubeadm.conf</span>
<span style=color:#b8860b>ExecStart</span><span style=color:#666>=</span>...--pod-infra-container-image<span style=color:#666>=</span>registry.cn-<span style=color:#666>[</span>hangzhou.aliyuncs.com/google_containers/pause:3.7 --<span style=color:#666>](</span>http://hangzhou.aliyuncs.com/google_containers/pause:3.7--<span style=color:#666>)</span>container-runtime-endpoint<span style=color:#666>=</span>unix:///var/run/cri-dockerd.sock --containerd<span style=color:#666>=</span>unix:///var/run/cri-dockerd.sock

systemctl daemon-reload
systemctl restart kubelet
</code></pre></div><h3 id=kubeadm集群初始化>kubeadm集群初始化</h3>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>kubeadm init --kubernetes-version<span style=color:#666>=</span>1.24.1 <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>--apiserver-advertise-address<span style=color:#666>=</span>192.168.81.20 <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>--image-repository registry.cn-h<span style=color:#666>[</span>angzhou.aliyuncs.com/google_containers<span style=color:#666>](</span>http://angzhou.aliyuncs.com/google_containers<span style=color:#666>)</span> <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>--service-cidr<span style=color:#666>=</span>10.96.0.0/12 <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>--pod-network-cidr<span style=color:#666>=</span>10.211.0.0/16 <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>--cri-socket unix:///var/run/cri-dockerd.sock <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>--ignore-preflight-errors<span style=color:#666>=</span>Swap

root@master:/data/softs# kubeadm init --kubernetes-version<span style=color:#666>=</span>1.24.1 <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>&gt; --apiserver-advertise-address<span style=color:#666>=</span>192.168.81.20 <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>&gt; --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>&gt; --service-cidr<span style=color:#666>=</span>10.96.0.0/12 <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>&gt; --pod-network-cidr<span style=color:#666>=</span>10.211.0.0/16 <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>&gt; --cri-socket unix:///var/run/cri-dockerd.sock <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>&gt; --ignore-preflight-errors<span style=color:#666>=</span>Swap
<span style=color:#666>[</span>init<span style=color:#666>]</span> Using Kubernetes version: v1.24.1
<span style=color:#666>[</span>preflight<span style=color:#666>]</span> Running pre-flight checks
<span style=color:#666>[</span>preflight<span style=color:#666>]</span> Pulling images required <span style=color:#a2f;font-weight:700>for</span> setting up a Kubernetes cluster
<span style=color:#666>[</span>preflight<span style=color:#666>]</span> This might take a minute or two, depending on the speed of your internet connection
<span style=color:#666>[</span>preflight<span style=color:#666>]</span> You can also perform this action in beforehand using <span style=color:#b44>&#39;kubeadm config images pull&#39;</span>
<span style=color:#666>[</span>certs<span style=color:#666>]</span> Using certificateDir folder <span style=color:#b44>&#34;/etc/kubernetes/pki&#34;</span>
<span style=color:#666>[</span>certs<span style=color:#666>]</span> Generating <span style=color:#b44>&#34;ca&#34;</span> certificate and key
<span style=color:#666>[</span>certs<span style=color:#666>]</span> Generating <span style=color:#b44>&#34;apiserver&#34;</span> certificate and key
<span style=color:#666>[</span>certs<span style=color:#666>]</span> apiserver serving cert is signed <span style=color:#a2f;font-weight:700>for</span> DNS names <span style=color:#666>[</span>kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local master<span style=color:#666>]</span> and IPs <span style=color:#666>[</span>10.96.0.1 192.168.81.20<span style=color:#666>]</span>
<span style=color:#666>[</span>certs<span style=color:#666>]</span> Generating <span style=color:#b44>&#34;apiserver-kubelet-client&#34;</span> certificate and key
<span style=color:#666>[</span>certs<span style=color:#666>]</span> Generating <span style=color:#b44>&#34;front-proxy-ca&#34;</span> certificate and key
<span style=color:#666>[</span>certs<span style=color:#666>]</span> Generating <span style=color:#b44>&#34;front-proxy-client&#34;</span> certificate and key
<span style=color:#666>[</span>certs<span style=color:#666>]</span> Generating <span style=color:#b44>&#34;etcd/ca&#34;</span> certificate and key
<span style=color:#666>[</span>certs<span style=color:#666>]</span> Generating <span style=color:#b44>&#34;etcd/server&#34;</span> certificate and key
<span style=color:#666>[</span>certs<span style=color:#666>]</span> etcd/server serving cert is signed <span style=color:#a2f;font-weight:700>for</span> DNS names <span style=color:#666>[</span>localhost master<span style=color:#666>]</span> and IPs <span style=color:#666>[</span>192.168.81.20 127.0.0.1 ::1<span style=color:#666>]</span>
<span style=color:#666>[</span>certs<span style=color:#666>]</span> Generating <span style=color:#b44>&#34;etcd/peer&#34;</span> certificate and key
<span style=color:#666>[</span>certs<span style=color:#666>]</span> etcd/peer serving cert is signed <span style=color:#a2f;font-weight:700>for</span> DNS names <span style=color:#666>[</span>localhost master<span style=color:#666>]</span> and IPs <span style=color:#666>[</span>192.168.81.20 127.0.0.1 ::1<span style=color:#666>]</span>
<span style=color:#666>[</span>certs<span style=color:#666>]</span> Generating <span style=color:#b44>&#34;etcd/healthcheck-client&#34;</span> certificate and key
<span style=color:#666>[</span>certs<span style=color:#666>]</span> Generating <span style=color:#b44>&#34;apiserver-etcd-client&#34;</span> certificate and key
<span style=color:#666>[</span>certs<span style=color:#666>]</span> Generating <span style=color:#b44>&#34;sa&#34;</span> key and public key
<span style=color:#666>[</span>kubeconfig<span style=color:#666>]</span> Using kubeconfig folder <span style=color:#b44>&#34;/etc/kubernetes&#34;</span>
<span style=color:#666>[</span>kubeconfig<span style=color:#666>]</span> Writing <span style=color:#b44>&#34;admin.conf&#34;</span> kubeconfig file
<span style=color:#666>[</span>kubeconfig<span style=color:#666>]</span> Writing <span style=color:#b44>&#34;kubelet.conf&#34;</span> kubeconfig file
<span style=color:#666>[</span>kubeconfig<span style=color:#666>]</span> Writing <span style=color:#b44>&#34;controller-manager.conf&#34;</span> kubeconfig file
<span style=color:#666>[</span>kubeconfig<span style=color:#666>]</span> Writing <span style=color:#b44>&#34;scheduler.conf&#34;</span> kubeconfig file
<span style=color:#666>[</span>kubelet-start<span style=color:#666>]</span> Writing kubelet environment file with flags to file <span style=color:#b44>&#34;/var/lib/kubelet/kubeadm-flags.env&#34;</span>
<span style=color:#666>[</span>kubelet-start<span style=color:#666>]</span> Writing kubelet configuration to file <span style=color:#b44>&#34;/var/lib/kubelet/config.yaml&#34;</span>
<span style=color:#666>[</span>kubelet-start<span style=color:#666>]</span> Starting the kubelet
<span style=color:#666>[</span>control-plane<span style=color:#666>]</span> Using manifest folder <span style=color:#b44>&#34;/etc/kubernetes/manifests&#34;</span>
<span style=color:#666>[</span>control-plane<span style=color:#666>]</span> Creating static Pod manifest <span style=color:#a2f;font-weight:700>for</span> <span style=color:#b44>&#34;kube-apiserver&#34;</span>
<span style=color:#666>[</span>control-plane<span style=color:#666>]</span> Creating static Pod manifest <span style=color:#a2f;font-weight:700>for</span> <span style=color:#b44>&#34;kube-controller-manager&#34;</span>
<span style=color:#666>[</span>control-plane<span style=color:#666>]</span> Creating static Pod manifest <span style=color:#a2f;font-weight:700>for</span> <span style=color:#b44>&#34;kube-scheduler&#34;</span>
<span style=color:#666>[</span>etcd<span style=color:#666>]</span> Creating static Pod manifest <span style=color:#a2f;font-weight:700>for</span> <span style=color:#a2f>local</span> etcd in <span style=color:#b44>&#34;/etc/kubernetes/manifests&#34;</span>
<span style=color:#666>[</span>wait-control-plane<span style=color:#666>]</span> Waiting <span style=color:#a2f;font-weight:700>for</span> the kubelet to boot up the control plane as static Pods from directory <span style=color:#b44>&#34;/etc/kubernetes/manifests&#34;</span>. This can take up to 4m0s
<span style=color:#666>[</span>apiclient<span style=color:#666>]</span> All control plane components are healthy after 9.002541 seconds
<span style=color:#666>[</span>upload-config<span style=color:#666>]</span> Storing the configuration used in ConfigMap <span style=color:#b44>&#34;kubeadm-config&#34;</span> in the <span style=color:#b44>&#34;kube-system&#34;</span> Namespace
<span style=color:#666>[</span>kubelet<span style=color:#666>]</span> Creating a ConfigMap <span style=color:#b44>&#34;kubelet-config&#34;</span> in namespace kube-system with the configuration <span style=color:#a2f;font-weight:700>for</span> the kubelets in the cluster
<span style=color:#666>[</span>upload-certs<span style=color:#666>]</span> Skipping phase. Please see --upload-certs
<span style=color:#666>[</span>mark-control-plane<span style=color:#666>]</span> Marking the node master as control-plane by adding the labels: <span style=color:#666>[</span>node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers<span style=color:#666>]</span>
<span style=color:#666>[</span>mark-control-plane<span style=color:#666>]</span> Marking the node master as control-plane by adding the taints <span style=color:#666>[</span>node-role.kubernetes.io/master:NoSchedule node-role.kubernetes.io/control-plane:NoSchedule<span style=color:#666>]</span>
<span style=color:#666>[</span>bootstrap-token<span style=color:#666>]</span> Using token: zpqirm.so0xmeo6b46gaj41
<span style=color:#666>[</span>bootstrap-token<span style=color:#666>]</span> Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
<span style=color:#666>[</span>bootstrap-token<span style=color:#666>]</span> Configured RBAC rules to allow Node Bootstrap tokens to get nodes
<span style=color:#666>[</span>bootstrap-token<span style=color:#666>]</span> Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order <span style=color:#a2f;font-weight:700>for</span> nodes to get long term certificate credentials
<span style=color:#666>[</span>bootstrap-token<span style=color:#666>]</span> Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
<span style=color:#666>[</span>bootstrap-token<span style=color:#666>]</span> Configured RBAC rules to allow certificate rotation <span style=color:#a2f;font-weight:700>for</span> all node client certificates in the cluster
<span style=color:#666>[</span>bootstrap-token<span style=color:#666>]</span> Creating the <span style=color:#b44>&#34;cluster-info&#34;</span> ConfigMap in the <span style=color:#b44>&#34;kube-public&#34;</span> namespace
<span style=color:#666>[</span>kubelet-finalize<span style=color:#666>]</span> Updating <span style=color:#b44>&#34;/etc/kubernetes/kubelet.conf&#34;</span> to point to a rotatable kubelet client certificate and key
<span style=color:#666>[</span>addons<span style=color:#666>]</span> Applied essential addon: CoreDNS
<span style=color:#666>[</span>addons<span style=color:#666>]</span> Applied essential addon: kube-proxy

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p <span style=color:#b8860b>$HOME</span>/.kube
  sudo cp -i /etc/kubernetes/admin.conf <span style=color:#b8860b>$HOME</span>/.kube/config
  sudo chown <span style=color:#a2f;font-weight:700>$(</span>id -u<span style=color:#a2f;font-weight:700>)</span>:<span style=color:#a2f;font-weight:700>$(</span>id -g<span style=color:#a2f;font-weight:700>)</span> <span style=color:#b8860b>$HOME</span>/.kube/config

Alternatively, <span style=color:#a2f;font-weight:700>if</span> you are the root user, you can run:

  <span style=color:#a2f>export</span> <span style=color:#b8860b>KUBECONFIG</span><span style=color:#666>=</span>/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run <span style=color:#b44>&#34;kubectl apply -f [podnetwork].yaml&#34;</span> with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 192.168.81.20:6443 --token zpqirm.so0xmeo6b46gaj41 <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>        --discovery-token-ca-cert-hash sha256:e8469d13b8ff07ce2803134048bb109a16e6b15b9e3279c4c556066549025c47
root@master:/data/softs# mkdir -p <span style=color:#b8860b>$HOME</span>/.kube
root@master:/data/softs#   sudo cp -i /etc/kubernetes/admin.conf <span style=color:#b8860b>$HOME</span>/.kube/config
root@master:/data/softs#   sudo chown <span style=color:#a2f;font-weight:700>$(</span>id -u<span style=color:#a2f;font-weight:700>)</span>:<span style=color:#a2f;font-weight:700>$(</span>id -g<span style=color:#a2f;font-weight:700>)</span> <span style=color:#b8860b>$HOME</span>/.kube/config
</code></pre></div><p>在worker节点</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@worker01:/data/softs# kubeadm join 192.168.81.20:6443 --token zpqirm.so0xmeo6b46gaj41 <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>&gt;         --discovery-token-ca-cert-hash sha256:e8469d13b8ff07ce2803134048bb109a16e6b15b9e3279c4c556066549025c47
Found multiple CRI endpoints on the host. Please define which one <span style=color:#a2f;font-weight:700>do</span> you wish to use by setting the <span style=color:#b44>&#39;criSocket&#39;</span> field in the kubeadm configuration file: unix:///var/run/containerd/containerd.sock, unix:///var/run/cri-dockerd.sock
To see the stack trace of this error execute with --v<span style=color:#666>=</span><span style=color:#666>5</span> or higher
</code></pre></div><p>这是因为底层的默认cri是containerd</p>
<p>执行kubeadm join加入CRI</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@worker01:/data/softs# kubeadm join 192.168.81.20:6443 --token zpqirm.so0xmeo6b46gaj41         --discovery-token-ca-cert-hash sha256:e8469d13b8ff07ce2803134048bb109a16e6b15b9e3279c4c556066549025c47  --cri-socket unix:///var/run/cri-dockerd.sock
<span style=color:#666>[</span>preflight<span style=color:#666>]</span> Running pre-flight checks
<span style=color:#666>[</span>preflight<span style=color:#666>]</span> Reading configuration from the cluster...
<span style=color:#666>[</span>preflight<span style=color:#666>]</span> FYI: You can look at this config file with <span style=color:#b44>&#39;kubectl -n kube-system get cm kubeadm-config -o yaml&#39;</span>
<span style=color:#666>[</span>kubelet-start<span style=color:#666>]</span> Writing kubelet configuration to file <span style=color:#b44>&#34;/var/lib/kubelet/config.yaml&#34;</span>
<span style=color:#666>[</span>kubelet-start<span style=color:#666>]</span> Writing kubelet environment file with flags to file <span style=color:#b44>&#34;/var/lib/kubelet/kubeadm-flags.env&#34;</span>
<span style=color:#666>[</span>kubelet-start<span style=color:#666>]</span> Starting the kubelet
<span style=color:#666>[</span>kubelet-start<span style=color:#666>]</span> Waiting <span style=color:#a2f;font-weight:700>for</span> the kubelet to perform the TLS Bootstrap...

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run <span style=color:#b44>&#39;kubectl get nodes&#39;</span> on the control-plane to see this node join the cluster.
</code></pre></div><h1 id=cri-o运行时创建集群>CRI-O运行时创建集群</h1>
<p>官网的文档</p>
<p><a href=https://kubernetes.io/zh/docs/setup/production-environment/container-runtimes/#cri-o>容器运行时</a></p>
<h2 id=安装cri-o>安装CRI-O</h2>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#b8860b>OS</span><span style=color:#666>=</span>xUbuntu_20.04
<span style=color:#b8860b>CRIO_VERSION</span><span style=color:#666>=</span>1.24
<span style=color:#a2f>echo</span> <span style=color:#b44>&#34;deb http://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/</span><span style=color:#b8860b>$OS</span><span style=color:#b44>/ /&#34;</span> | sudo tee /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list
<span style=color:#a2f>echo</span> <span style=color:#b44>&#34;deb http://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/</span><span style=color:#b8860b>$CRIO_VERSION</span><span style=color:#b44>/</span><span style=color:#b8860b>$OS</span><span style=color:#b44>/ /&#34;</span> | sudo tee /etc/apt/sources.list.d/devel:kubic:libcontainers:stable:cri-o:<span style=color:#b8860b>$CRIO_VERSION</span>.list

curl -L https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable:cri-o:<span style=color:#b8860b>$CRIO_VERSION</span>/<span style=color:#b8860b>$OS</span>/Release.key | sudo apt-key add -
curl -L https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/<span style=color:#b8860b>$OS</span>/Release.key | sudo apt-key add -

<span style=color:#080;font-style:italic>#echo &#34;deb [signed-by=/usr/share/keyrings/libcontainers-archive-keyring.gpg] https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/$OS/ /&#34; &gt; /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list</span>
<span style=color:#080;font-style:italic>#echo &#34;deb [signed-by=/usr/share/keyrings/libcontainers-crio-archive-keyring.gpg] https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/$VERSION/$OS/ /&#34; &gt; /etc/apt/sources.list.d/devel:kubic:libcontainers:stable:cri-o:$VERSION.list</span>

<span style=color:#080;font-style:italic>#mkdir -p /usr/share/keyrings</span>
<span style=color:#080;font-style:italic>#curl -L https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/$OS/Release.key | gpg --dearmor -o /usr/share/keyrings/libcontainers-archive-keyring.gpg</span>
<span style=color:#080;font-style:italic>#curl -L https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/$VERSION/$OS/Release.key | gpg --dearmor -o /usr/share/keyrings/libcontainers-crio-archive-keyring.gpg</span>

apt-get update
apt-get install cri-o cri-o-runc

systemctl start crio
systemctl <span style=color:#a2f>enable</span> crio
systemctl status crio
</code></pre></div><h2 id=修改配置>修改配置</h2>
<h3 id=修改默认的网段>修改默认的网段</h3>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#080;font-style:italic>#/etc/cni/net．d/100-crio-bridge．conf</span>
sed -i <span style=color:#b44>&#39;s/10.85.0.0/10.211.0.0/g&#39;</span> /etc/cni/net.d/100-crio-bridge.conf

</code></pre></div><h3 id=修改基本的配置>修改基本的配置</h3>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#080;font-style:italic>#grep -Env &#39;#|^$|^\[&#39;/etc/crio/crio.conf</span>
169:cgroup_manager <span style=color:#666>=</span> <span style=color:#b44>&#34;systemd&#34;</span>
451:pause_image <span style=color:#666>=</span><span style=color:#b44>&#34;[registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6](http://registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.6)&#34;</span>
</code></pre></div><p>重启服务配置</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>systemctl restart crio

</code></pre></div><p>验证效果</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>curl -v --unix-socket /var/run/crio/crio.sock <span style=color:#666>[</span>http://localhost/info<span style=color:#666>](</span>http://localhost/info<span style=color:#666>)</span>

root@first:~# curl -v --unix-socket /var/run/crio/crio.sock http://localhost/info
*   Trying /var/run/crio/crio.sock:0...
* Connected to localhost <span style=color:#666>(</span>/var/run/crio/crio.sock<span style=color:#666>)</span> port <span style=color:#666>80</span> <span style=color:#666>(</span><span style=color:#080;font-style:italic>#0)</span>
&gt; GET /info HTTP/1.1
&gt; Host: localhost
&gt; User-Agent: curl/7.68.0
&gt; Accept: */*
&gt;
* Mark bundle as not supporting multiuse
&lt; HTTP/1.1 <span style=color:#666>200</span> OK
&lt; Content-Type: application/json
&lt; Date: Sat, <span style=color:#666>04</span> Jun <span style=color:#666>2022</span> 15:10:27 GMT
&lt; Content-Length: <span style=color:#666>239</span>
&lt;
* Connection <span style=color:#080;font-style:italic>#0 to host localhost left intact</span>
<span style=color:#666>{</span><span style=color:#b44>&#34;storage_driver&#34;</span>:<span style=color:#b44>&#34;overlay&#34;</span>,<span style=color:#b44>&#34;storage_root&#34;</span>:<span style=color:#b44>&#34;/var/lib/containers/storage&#34;</span>,<span style=color:#b44>&#34;cgroup_driver&#34;</span>:<span style=color:#b44>&#34;systemd&#34;</span>,<span style=color:#b44>&#34;default_id_mappings&#34;</span>:<span style=color:#666>{</span><span style=color:#b44>&#34;uids&#34;</span>:<span style=color:#666>[{</span><span style=color:#b44>&#34;container_id&#34;</span>:0,<span style=color:#b44>&#34;host_id&#34;</span>:0,<span style=color:#b44>&#34;size&#34;</span>:4294967295<span style=color:#666>}]</span>,<span style=color:#b44>&#34;gids&#34;</span>:<span style=color:#666>[{</span><span style=color:#b44>&#34;container_id&#34;</span>:0,<span style=color:#b44>&#34;host_id&#34;</span>:0,<span style=color:#b44>&#34;size&#34;</span>:4294967295<span style=color:#666>}]}}</span>
</code></pre></div><h3 id=配置crictlyaml参数>配置crictl.yaml参数</h3>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#080;font-style:italic># cat /etc/crictl.yaml</span>
runtime-endpoint: <span style=color:#b44>&#34;unix:///var/run/crio/crio.sock&#34;</span>
image-endpoint: <span style=color:#b44>&#34;unix:///var/run/crio/crio.sock&#34;</span>
timeout: <span style=color:#666>10</span>
debug: <span style=color:#a2f>false</span>
pull-image-on-create: <span style=color:#a2f>true</span>
disable-pull-on-run: <span style=color:#a2f>false</span>

</code></pre></div><h2 id=初始化集群>初始化集群</h2>
<h3 id=修改kubelet参数>修改kubelet参数</h3>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#080;font-style:italic>#cat/etc/systemd/system/kubelet.service.d/10-kubeadm.conf</span>
<span style=color:#b8860b>ExecStart</span><span style=color:#666>=</span>...--container-runtime<span style=color:#666>=</span>remote --cgroup-driver<span style=color:#666>=</span>systemd --container-runtime-endpoint<span style=color:#666>=</span><span style=color:#b44>&#39;unix:///var/run/crio/crio.sock&#39;</span> --runtime-request-timeout<span style=color:#666>=</span>5m

systemctl daemon-reload
systemctl restart kubelet
</code></pre></div><h3 id=集群初始化>集群初始化</h3>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>kubeadm init --kubernetes-version<span style=color:#666>=</span>1.24.1 <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>--apiserver-advertise-address<span style=color:#666>=</span>192.168.81.1 <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>--image-repository<span style=color:#666>=</span>registry.cn-<span style=color:#666>[</span>hangzhou.aliyuncs.com/google_containers <span style=color:#b62;font-weight:700>\]</span><span style=color:#666>(</span>http://hangzhou.aliyuncs.com/google_containers%5C<span style=color:#666>)</span>
--service-cidr<span style=color:#666>=</span>10.96.0.0/12 <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>--pod-network-cidr<span style=color:#666>=</span>10.211.0.0/16 <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>--cri-socket unix:///var/run/crio/crio.sock <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>--ignore-preflight-errors<span style=color:#666>=</span>Swap

root@main:~# kubeadm init --kubernetes-version<span style=color:#666>=</span>1.24.1 <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>&gt; --apiserver-advertise-address<span style=color:#666>=</span>192.168.81.1 <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>&gt; --image-repository<span style=color:#666>=</span>registry.cn-hangzhou.aliyuncs.com/google_containers <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>&gt; --service-cidr<span style=color:#666>=</span>10.96.0.0/12 <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>&gt; --pod-network-cidr<span style=color:#666>=</span>10.211.0.0/16 <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>&gt; --cri-socket unix:///var/run/crio/crio.sock <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>&gt; --ignore-preflight-errors<span style=color:#666>=</span>Swap
<span style=color:#666>[</span>init<span style=color:#666>]</span> Using Kubernetes version: v1.24.1
<span style=color:#666>[</span>preflight<span style=color:#666>]</span> Running pre-flight checks
<span style=color:#666>[</span>preflight<span style=color:#666>]</span> Pulling images required <span style=color:#a2f;font-weight:700>for</span> setting up a Kubernetes cluster
<span style=color:#666>[</span>preflight<span style=color:#666>]</span> This might take a minute or two, depending on the speed of your internet connection
<span style=color:#666>[</span>preflight<span style=color:#666>]</span> You can also perform this action in beforehand using <span style=color:#b44>&#39;kubeadm config images pull&#39;</span>
<span style=color:#666>[</span>certs<span style=color:#666>]</span> Using certificateDir folder <span style=color:#b44>&#34;/etc/kubernetes/pki&#34;</span>
<span style=color:#666>[</span>certs<span style=color:#666>]</span> Generating <span style=color:#b44>&#34;ca&#34;</span> certificate and key
<span style=color:#666>[</span>certs<span style=color:#666>]</span> Generating <span style=color:#b44>&#34;apiserver&#34;</span> certificate and key
<span style=color:#666>[</span>certs<span style=color:#666>]</span> apiserver serving cert is signed <span style=color:#a2f;font-weight:700>for</span> DNS names <span style=color:#666>[</span>kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local main<span style=color:#666>]</span> and IPs <span style=color:#666>[</span>10.96.0.1 192.168.81.1<span style=color:#666>]</span>
<span style=color:#666>[</span>certs<span style=color:#666>]</span> Generating <span style=color:#b44>&#34;apiserver-kubelet-client&#34;</span> certificate and key
<span style=color:#666>[</span>certs<span style=color:#666>]</span> Generating <span style=color:#b44>&#34;front-proxy-ca&#34;</span> certificate and key
<span style=color:#666>[</span>certs<span style=color:#666>]</span> Generating <span style=color:#b44>&#34;front-proxy-client&#34;</span> certificate and key
<span style=color:#666>[</span>certs<span style=color:#666>]</span> Generating <span style=color:#b44>&#34;etcd/ca&#34;</span> certificate and key
<span style=color:#666>[</span>certs<span style=color:#666>]</span> Generating <span style=color:#b44>&#34;etcd/server&#34;</span> certificate and key
<span style=color:#666>[</span>certs<span style=color:#666>]</span> etcd/server serving cert is signed <span style=color:#a2f;font-weight:700>for</span> DNS names <span style=color:#666>[</span>localhost main<span style=color:#666>]</span> and IPs <span style=color:#666>[</span>192.168.81.1 127.0.0.1 ::1<span style=color:#666>]</span>
<span style=color:#666>[</span>certs<span style=color:#666>]</span> Generating <span style=color:#b44>&#34;etcd/peer&#34;</span> certificate and key
<span style=color:#666>[</span>certs<span style=color:#666>]</span> etcd/peer serving cert is signed <span style=color:#a2f;font-weight:700>for</span> DNS names <span style=color:#666>[</span>localhost main<span style=color:#666>]</span> and IPs <span style=color:#666>[</span>192.168.81.1 127.0.0.1 ::1<span style=color:#666>]</span>
<span style=color:#666>[</span>certs<span style=color:#666>]</span> Generating <span style=color:#b44>&#34;etcd/healthcheck-client&#34;</span> certificate and key
<span style=color:#666>[</span>certs<span style=color:#666>]</span> Generating <span style=color:#b44>&#34;apiserver-etcd-client&#34;</span> certificate and key
<span style=color:#666>[</span>certs<span style=color:#666>]</span> Generating <span style=color:#b44>&#34;sa&#34;</span> key and public key
<span style=color:#666>[</span>kubeconfig<span style=color:#666>]</span> Using kubeconfig folder <span style=color:#b44>&#34;/etc/kubernetes&#34;</span>
<span style=color:#666>[</span>kubeconfig<span style=color:#666>]</span> Writing <span style=color:#b44>&#34;admin.conf&#34;</span> kubeconfig file
<span style=color:#666>[</span>kubeconfig<span style=color:#666>]</span> Writing <span style=color:#b44>&#34;kubelet.conf&#34;</span> kubeconfig file
<span style=color:#666>[</span>kubeconfig<span style=color:#666>]</span> Writing <span style=color:#b44>&#34;controller-manager.conf&#34;</span> kubeconfig file
<span style=color:#666>[</span>kubeconfig<span style=color:#666>]</span> Writing <span style=color:#b44>&#34;scheduler.conf&#34;</span> kubeconfig file
<span style=color:#666>[</span>kubelet-start<span style=color:#666>]</span> Writing kubelet environment file with flags to file <span style=color:#b44>&#34;/var/lib/kubelet/kubeadm-flags.env&#34;</span>
<span style=color:#666>[</span>kubelet-start<span style=color:#666>]</span> Writing kubelet configuration to file <span style=color:#b44>&#34;/var/lib/kubelet/config.yaml&#34;</span>
<span style=color:#666>[</span>kubelet-start<span style=color:#666>]</span> Starting the kubelet
<span style=color:#666>[</span>control-plane<span style=color:#666>]</span> Using manifest folder <span style=color:#b44>&#34;/etc/kubernetes/manifests&#34;</span>
<span style=color:#666>[</span>control-plane<span style=color:#666>]</span> Creating static Pod manifest <span style=color:#a2f;font-weight:700>for</span> <span style=color:#b44>&#34;kube-apiserver&#34;</span>
<span style=color:#666>[</span>control-plane<span style=color:#666>]</span> Creating static Pod manifest <span style=color:#a2f;font-weight:700>for</span> <span style=color:#b44>&#34;kube-controller-manager&#34;</span>
<span style=color:#666>[</span>control-plane<span style=color:#666>]</span> Creating static Pod manifest <span style=color:#a2f;font-weight:700>for</span> <span style=color:#b44>&#34;kube-scheduler&#34;</span>
<span style=color:#666>[</span>etcd<span style=color:#666>]</span> Creating static Pod manifest <span style=color:#a2f;font-weight:700>for</span> <span style=color:#a2f>local</span> etcd in <span style=color:#b44>&#34;/etc/kubernetes/manifests&#34;</span>
<span style=color:#666>[</span>wait-control-plane<span style=color:#666>]</span> Waiting <span style=color:#a2f;font-weight:700>for</span> the kubelet to boot up the control plane as static Pods from directory <span style=color:#b44>&#34;/etc/kubernetes/manifests&#34;</span>. This can take up to 4m0s
<span style=color:#666>[</span>apiclient<span style=color:#666>]</span> All control plane components are healthy after 7.003679 seconds
<span style=color:#666>[</span>upload-config<span style=color:#666>]</span> Storing the configuration used in ConfigMap <span style=color:#b44>&#34;kubeadm-config&#34;</span> in the <span style=color:#b44>&#34;kube-system&#34;</span> Namespace
<span style=color:#666>[</span>kubelet<span style=color:#666>]</span> Creating a ConfigMap <span style=color:#b44>&#34;kubelet-config&#34;</span> in namespace kube-system with the configuration <span style=color:#a2f;font-weight:700>for</span> the kubelets in the cluster
<span style=color:#666>[</span>upload-certs<span style=color:#666>]</span> Skipping phase. Please see --upload-certs
<span style=color:#666>[</span>mark-control-plane<span style=color:#666>]</span> Marking the node main as control-plane by adding the labels: <span style=color:#666>[</span>node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers<span style=color:#666>]</span>
<span style=color:#666>[</span>mark-control-plane<span style=color:#666>]</span> Marking the node main as control-plane by adding the taints <span style=color:#666>[</span>node-role.kubernetes.io/master:NoSchedule node-role.kubernetes.io/control-plane:NoSchedule<span style=color:#666>]</span>
<span style=color:#666>[</span>bootstrap-token<span style=color:#666>]</span> Using token: k9dmq6.cuhj0atd4jhz4y6o
<span style=color:#666>[</span>bootstrap-token<span style=color:#666>]</span> Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
<span style=color:#666>[</span>bootstrap-token<span style=color:#666>]</span> Configured RBAC rules to allow Node Bootstrap tokens to get nodes
<span style=color:#666>[</span>bootstrap-token<span style=color:#666>]</span> Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order <span style=color:#a2f;font-weight:700>for</span> nodes to get long term certificate credentials
<span style=color:#666>[</span>bootstrap-token<span style=color:#666>]</span> Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
<span style=color:#666>[</span>bootstrap-token<span style=color:#666>]</span> Configured RBAC rules to allow certificate rotation <span style=color:#a2f;font-weight:700>for</span> all node client certificates in the cluster
<span style=color:#666>[</span>bootstrap-token<span style=color:#666>]</span> Creating the <span style=color:#b44>&#34;cluster-info&#34;</span> ConfigMap in the <span style=color:#b44>&#34;kube-public&#34;</span> namespace
<span style=color:#666>[</span>kubelet-finalize<span style=color:#666>]</span> Updating <span style=color:#b44>&#34;/etc/kubernetes/kubelet.conf&#34;</span> to point to a rotatable kubelet client certificate and key
<span style=color:#666>[</span>addons<span style=color:#666>]</span> Applied essential addon: CoreDNS
<span style=color:#666>[</span>addons<span style=color:#666>]</span> Applied essential addon: kube-proxy

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p <span style=color:#b8860b>$HOME</span>/.kube
  sudo cp -i /etc/kubernetes/admin.conf <span style=color:#b8860b>$HOME</span>/.kube/config
  sudo chown <span style=color:#a2f;font-weight:700>$(</span>id -u<span style=color:#a2f;font-weight:700>)</span>:<span style=color:#a2f;font-weight:700>$(</span>id -g<span style=color:#a2f;font-weight:700>)</span> <span style=color:#b8860b>$HOME</span>/.kube/config

Alternatively, <span style=color:#a2f;font-weight:700>if</span> you are the root user, you can run:

  <span style=color:#a2f>export</span> <span style=color:#b8860b>KUBECONFIG</span><span style=color:#666>=</span>/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run <span style=color:#b44>&#34;kubectl apply -f [podnetwork].yaml&#34;</span> with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 192.168.81.1:6443 --token k9dmq6.cuhj0atd4jhz4y6o <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>        --discovery-token-ca-cert-hash sha256:99de4906a2f690147d59ee71c1e2e916e64b6a8f6efae5bd28bebcb711cd28ab
</code></pre></div><p>Worker 加入集群</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>root@worker03:~# kubeadm join 192.168.81.1:6443 --token k9dmq6.cuhj0atd4jhz4y6o <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>&gt;         --discovery-token-ca-cert-hash sha256:99de4906a2f690147d59ee71c1e2e916e64b6a8f6efae5bd28bebcb711cd28ab
<span style=color:#666>[</span>preflight<span style=color:#666>]</span> Running pre-flight checks
<span style=color:#666>[</span>preflight<span style=color:#666>]</span> Reading configuration from the cluster...
<span style=color:#666>[</span>preflight<span style=color:#666>]</span> FYI: You can look at this config file with <span style=color:#b44>&#39;kubectl -n kube-system get cm kubeadm-config -o yaml&#39;</span>
<span style=color:#666>[</span>kubelet-start<span style=color:#666>]</span> Writing kubelet configuration to file <span style=color:#b44>&#34;/var/lib/kubelet/config.yaml&#34;</span>
<span style=color:#666>[</span>kubelet-start<span style=color:#666>]</span> Writing kubelet environment file with flags to file <span style=color:#b44>&#34;/var/lib/kubelet/kubeadm-flags.env&#34;</span>
<span style=color:#666>[</span>kubelet-start<span style=color:#666>]</span> Starting the kubelet
<span style=color:#666>[</span>kubelet-start<span style=color:#666>]</span> Waiting <span style=color:#a2f;font-weight:700>for</span> the kubelet to perform the TLS Bootstrap...

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run <span style=color:#b44>&#39;kubectl get nodes&#39;</span> on the control-plane to see this node join the cluster.
</code></pre></div>
</div>
<footer class=post-footer>
<div id=wcomments></div>
</footer>
</article>
</section>
</div>
</div>
<div class=sidebar-toggle>
<div class=sidebar-toggle-line-wrap>
<span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
<span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
<span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
</div>
</div>
<aside id=sidebar class=sidebar>
<div class=sidebar-inner>
<ul class="sidebar-nav motion-element">
<li class="sidebar-nav-toc sidebar-nav-active" data-target=post-toc-wrap>
文章目录
</li>
<li class=sidebar-nav-overview data-target=site-overview>
站点概览
</li>
</ul>
<section class="site-overview sidebar-panel">
<div class="site-author motion-element" itemprop=author itemscope itemtype=http://schema.org/Person>
<img class=site-author-image itemprop=image src=/img/avatar.png alt=Etaon>
<p class=site-author-name itemprop=name>Etaon</p>
<p class="site-description motion-element" itemprop=description>
Kepp Going!
</p>
</div>
<nav class="site-state motion-element">
<div class="site-state-item site-state-posts">
<a href=/post/>
<span class=site-state-item-count>61</span>
<span class=site-state-item-name>日志</span>
</a>
</div>
<div class="site-state-item site-state-categories">
<a href=/categories/>
<span class=site-state-item-count>13</span>
<span class=site-state-item-name>分类</span>
</a>
</div>
<div class="site-state-item site-state-tags">
<a href=/tags/>
<span class=site-state-item-count>34</span>
<span class=site-state-item-name>标签</span>
</a>
</div>
</nav>
<div class="links-of-author motion-element">
<span class=links-of-author-item>
<a href=https://github.com/etaon target=_blank title=GitHub>
<i class="fa fa-fw fa-github"></i>
GitHub
</a>
</span>
<span class=links-of-author-item>
<a href=https://blog.csdn.net/weixin_43394724 target=_blank title=CSDN>
<i class="fa fa-fw fa-CSDN"></i>
CSDN
</a>
</span>
</div>
<div class="links-of-blogroll motion-element links-of-blogroll-inline">
<div class=links-of-blogroll-title>
<i class="fa fa-fw fa-globe"></i>
友情链接
</div>
<ul class=links-of-blogroll-list>
<li class=links-of-blogroll-item>
<a href=https://kubernetes.io/ title=Kubernetes target=_blank>Kubernetes</a>
</li>
<li class=links-of-blogroll-item>
<a href=https://cisco.com/ title=Cisco target=_blank>Cisco</a>
</li>
<li class=links-of-blogroll-item>
<a href=https://www.w3school.com.cn/ title=W3School target=_blank>W3School</a>
</li>
<li class=links-of-blogroll-item>
<a href=https://www.liaoxuefeng.com/ title=廖雪峰 target=_blank>廖雪峰</a>
</li>
</ul>
</div>
<div class="tagcloud-of-blogroll motion-element tagcloud-of-blogroll-inline">
<div class=tagcloud-of-blogroll-title>
<i class="fa fa-fw fa-tags"></i>
标签云
</div>
<ul class=tagcloud-of-blogroll-list>
<li class=tagcloud-of-blogroll-item>
<a href=/tags/mysql>Mysql</a>
</li>
<li class=tagcloud-of-blogroll-item>
<a href=/tags/aws>Aws</a>
</li>
<li class=tagcloud-of-blogroll-item>
<a href=/tags/dql>Dql</a>
</li>
<li class=tagcloud-of-blogroll-item>
<a href=/tags/hadoop>Hadoop</a>
</li>
<li class=tagcloud-of-blogroll-item>
<a href=/tags/redis>Redis</a>
</li>
<li class=tagcloud-of-blogroll-item>
<a href=/tags/cicd>Cicd</a>
</li>
<li class=tagcloud-of-blogroll-item>
<a href=/tags/git>Git</a>
</li>
<li class=tagcloud-of-blogroll-item>
<a href=/tags/istio>Istio</a>
</li>
<li class=tagcloud-of-blogroll-item>
<a href=/tags/mongodb>Mongodb</a>
</li>
<li class=tagcloud-of-blogroll-item>
<a href=/tags/azure>Azure</a>
</li>
</ul>
</div>
</section>
<section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
<div class=post-toc>
<div class=post-toc-content><nav id=TableOfContents>
<ul>
<li><a href=#概述>概述</a></li>
<li><a href=#前置条件>前置条件</a></li>
<li><a href=#before-you-begin><strong>Before you begin</strong></a></li>
<li><a href=#软件部署>软件部署</a></li>
</ul>
<ul>
<li><a href=#安装containerd>安装Containerd</a>
<ul>
<li><a href=#在线安装方式>在线安装方式</a></li>
<li><a href=#离线安装方式>离线安装方式</a></li>
</ul>
</li>
<li><a href=#kubeadm初始化集群>Kubeadm初始化集群</a></li>
</ul>
<ul>
<li><a href=#安装docker-ce>安装Docker-ce</a></li>
<li><a href=#获取cri-dockers插件以支持docker>获取cri-dockers插件以支持docker</a></li>
<li><a href=#创建集群>创建集群</a>
<ul>
<li><a href=#kubelet改造所有node>kubelet改造，所有node</a></li>
<li><a href=#kubeadm集群初始化>kubeadm集群初始化</a></li>
</ul>
</li>
</ul>
<ul>
<li><a href=#安装cri-o>安装CRI-O</a></li>
<li><a href=#修改配置>修改配置</a>
<ul>
<li><a href=#修改默认的网段>修改默认的网段</a></li>
<li><a href=#修改基本的配置>修改基本的配置</a></li>
<li><a href=#配置crictlyaml参数>配置crictl.yaml参数</a></li>
</ul>
</li>
<li><a href=#初始化集群>初始化集群</a>
<ul>
<li><a href=#修改kubelet参数>修改kubelet参数</a></li>
<li><a href=#集群初始化>集群初始化</a></li>
</ul>
</li>
</ul>
</nav></div>
</div>
</section>
</div>
</aside>
</div>
</main>
<footer id=footer class=footer>
<div class=footer-inner>
<div class=copyright>
<span class=copyright-year>
&copy; 2010 - 2022
</span>
<span class=with-love><i class="fa fa-heart"></i></span>
<span class=copyright-author>路无止境！</span>
</div>
<div class=powered-info>
<span class=powered-by>
Powered by - <a class=powered-link href=//gohugo.io target=_blank title=hugo>Hugo v0.91.2</a>
</span>
<span class=separator-line>/</span>
<span class=theme-info>
Theme by - <a class=powered-link href=//github.com/elkan1788/hugo-theme-next target=_blank> NexT
</a>
</span>
</div>
<div class=vistor-info>
<script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script>
<span class=site-uv>
<i class="fa fa-user"></i>
<span class=busuanzi-value id=busuanzi_value_site_uv></span>
</span>
<span class=separator-line>/</span>
<span class=site-pv>
<i class="fa fa-eye"></i>
<span class=busuanzi-value id=busuanzi_value_site_pv></span>
</span>
</div>
<div class=license-info>
<span class=storage-info>
Storage by
<a href=https://www.azure.com/ style=font-weight:700 target=_blank>Azure static web apps</a>
</span>
<span class=separator-line>/</span>
<span class=license-num>
<a href target=_blank></a>
</span>
</div>
</div>
</footer>
<div class=back-to-top>
<i class="fa fa-arrow-up"></i>
<span id=scrollpercent><span>0</span>%</span>
</div>
</div>
<script type=text/javascript src=//cdn.bootcdn.net/ajax/libs/jquery/2.1.4/jquery.min.js></script>
<script type=text/javascript src=/js/search.js></script>
<script type=text/javascript src=/js/affix.js></script>
<script type=text/javascript src=/js/scrollspy.js></script>
<script type=text/javascript>function detectIE(){var a=window.navigator.userAgent,b=a.indexOf('MSIE '),c=a.indexOf('Trident/'),d=a.indexOf('Edge/');return b>0||c>0||d>0?-1:1}function getCntViewHeight(){var b=$('#content').height(),a=$(window).height(),c=b>a?b-a:$(document).height()-a;return c}function getScrollbarWidth(){var a=$('<div />').addClass('scrollbar-measure').prependTo('body'),b=a[0],c=b.offsetWidth-b.clientWidth;return a.remove(),c}function registerBackTop(){var b=50,a=$('.back-to-top');$(window).on('scroll',function(){var d,e,f,c,g;a.toggleClass('back-to-top-on',window.pageYOffset>b),d=$(window).scrollTop(),e=getCntViewHeight(),f=d/e,c=Math.round(f*100),g=c>100?100:c,$('#scrollpercent>span').html(g)}),a.on('click',function(){$("html,body").animate({scrollTop:0,screenLeft:0},800)})}function initScrollSpy(){var a='.post-toc',d=$(a),b='.active-current';d.on('activate.bs.scrollspy',function(){var b=$(a+' .active').last();c(),b.addClass('active-current')}).on('clear.bs.scrollspy',c),$('body').scrollspy({target:a});function c(){$(a+' '+b).removeClass(b.substring(1))}}function initAffix(){var a=$('.header-inner').height(),b=parseInt($('.main').css('padding-bottom'),10),c=a+10;$('.sidebar-inner').affix({offset:{top:c,bottom:b}}),$(document).on('affixed.bs.affix',function(){updateTOCHeight(document.body.clientHeight-100)})}function initTOCDimension(){var a,b;$(window).on('resize',function(){a&&clearTimeout(a),a=setTimeout(function(){var a=document.body.clientHeight-100;updateTOCHeight(a)},0)}),updateTOCHeight(document.body.clientHeight-100),b=getScrollbarWidth(),$('.post-toc').css('width','calc(100% + '+b+'px)')}function updateTOCHeight(a){a=a||'auto',$('.post-toc').css('max-height',a)}$(function(){var b=$('.header-inner').height()+10,c,d,a,e;$('#sidebar').css({'margin-top':b}).show(),c=parseInt($('#sidebar').css('margin-top')),d=parseInt($('.sidebar-inner').css('height')),a=c+d,e=$('.content-wrap').height(),e<a&&$('.content-wrap').css('min-height',a),$('.site-nav-toggle').on('click',function(){var a=$('.site-nav'),e=$('.toggle'),b='site-nav-on',f='toggle-close',c=a.hasClass(b),g=c?'slideUp':'slideDown',d=c?'removeClass':'addClass';a.stop()[g]('normal',function(){a[d](b),e[d](f)})}),registerBackTop(),initScrollSpy(),initAffix(),initTOCDimension(),$('.sidebar-nav-toc').click(function(){$(this).addClass('sidebar-nav-active'),$(this).next().removeClass('sidebar-nav-active'),$('.'+$(this).next().attr('data-target')).toggle(500),$('.'+$(this).attr('data-target')).toggle(500)}),$('.sidebar-nav-overview').click(function(){$(this).addClass('sidebar-nav-active'),$(this).prev().removeClass('sidebar-nav-active'),$('.'+$(this).prev().attr('data-target')).toggle(500),$('.'+$(this).attr('data-target')).toggle(500)})})</script>
<script src=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.js></script>
<script type=text/javascript>$(function(){$('.post-body').viewer()})</script>
<script type=text/javascript>$(function(){detectIE()>0?$.getScript(document.location.protocol+'//cdn.jsdelivr.net/npm/@waline/client/dist/Waline.min.js',function(){new Waline({el:'#wcomments',visitor:!0,avatar:'wavatar',avatarCDN:'https://sdn.geekzu.org/avatar/',avatarForce:!1,wordLimit:'200',placeholder:' 欢迎留下您的宝贵建议，请填写您的昵称和邮箱便于后续交流. ^_^ ',requiredFields:['nick','mail'],serverURL:"Your WalineSerURL",lang:"zh-cn"})}):$('#wcomments').html('抱歉，Waline插件不支持IE或Edge，建议使用Chrome浏览器。')})</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_SVG"></script>
<script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=Your%20AddthisId"></script>
<script>(function(){var a=document.createElement('script'),c=window.location.protocol.split(':')[0],b;c==='https'?a.src='https://zz.bdstatic.com/linksubmit/push.js':a.src='http://push.zhanzhang.baidu.com/push.js',b=document.getElementsByTagName("script")[0],b.parentNode.insertBefore(a,b)})()</script>
</body>
</html>